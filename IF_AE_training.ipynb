{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fd70ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:38:42 +  0.00s] â–¶ Load FINANCIAL (income) ...\n",
      "[20:38:42 +  0.30s] FIN rows=33773, null income=3264\n",
      "[20:38:42 +  0.30s] âœ“ Load FINANCIAL (income) done in 0.30s\n",
      "[20:38:42 +  0.30s] â–¶ Load HEALTH (poor general health %) ...\n",
      "[20:38:42 +  0.51s] HEALTH rows=32520, null health%=0\n",
      "[20:38:42 +  0.51s] âœ“ Load HEALTH (poor general health %) done in 0.21s\n",
      "[20:38:42 +  0.51s] â–¶ Load PHARMACY (access proxy) ...\n",
      "[20:38:43 +  1.02s] PHARMACY unique ZCTA5=14940, total pharmacies=61970\n",
      "[20:38:43 +  1.02s] âœ“ Load PHARMACY (access proxy) done in 0.50s\n",
      "[20:38:43 +  1.02s] â–¶ Load POPULATION (skiprows=10 heuristic + autodetect) ...\n",
      "[20:38:43 +  1.06s] POP rows=40959, null pop=0, land_col=None\n",
      "[20:38:43 +  1.06s] âœ“ Load POPULATION (skiprows=10 heuristic + autodetect) done in 0.05s\n",
      "[20:38:43 +  1.07s] â–¶ Merge all features by ZCTA/ZIP ...\n",
      "[20:38:43 +  1.10s] Merged shape: (41094, 5)\n",
      "Top null counts:\n",
      " pharmacies_count    26171\n",
      "S1901_C01_012E      10585\n",
      "GHLTH_CrudePrev      8574\n",
      "population            135\n",
      "ZCTA5                   0\n",
      "[20:38:43 +  1.10s] âœ“ Merge all features by ZCTA/ZIP done in 0.03s\n",
      "[20:38:43 +  1.10s] â–¶ Feature engineering ...\n",
      "[20:38:43 +  1.10s] Range median_income: min=6229.000 max=249688.000 NaN=10585\n",
      "[20:38:43 +  1.10s] Range poor_health_pct: min=3.600 max=56.500 NaN=8574\n",
      "[20:38:43 +  1.10s] Range pharm_per_10k: min=0.000 max=2000.000 NaN=1064\n",
      "[20:38:43 +  1.10s] Range population: min=0.000 max=122814.000 NaN=135\n",
      "[20:38:43 +  1.10s] Range pop_density: min=nan max=nan NaN=41094\n",
      "[20:38:43 +  1.10s] âœ“ Feature engineering done in 0.00s\n",
      "[20:38:43 +  1.10s] â–¶ Compute composite & train IsolationForest ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/5gzqwh3d5sx43n9fsy97czyc0000gn/T/ipykernel_54177/3424445507.py:210: RuntimeWarning: All-NaN axis encountered\n",
      "  stamp(f\"Range {col}: min={np.nanmin(x):.3f} max={np.nanmax(x):.3f} NaN={np.isnan(x).sum()}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:38:44 +  1.79s] âœ“ Compute composite & train IsolationForest done in 0.69s\n",
      "[20:38:44 +  1.79s] â–¶ Finalize outputs ...\n",
      "[20:38:44 +  1.98s] Wrote results/national_ifae_rank.csv\n",
      "[20:38:44 +  1.98s] Wrote results/top5_ifae.csv\n",
      "\n",
      "Top 5 preview:\n",
      " ZCTA5  IFAE_score  composite  iforest_anomaly  median_income  poor_health_pct  population  pharmacies_count  pharm_per_10k  income_norm_inv  health_norm  access_norm_inv  pop_norm  density_norm  pop_density\n",
      "96854    0.195164   0.250390         0.139938            NaN              NaN       599.0               0.0            0.0              NaN          NaN              1.0  0.004877           0.0          NaN\n",
      "65636    0.195164   0.250390         0.139938            NaN              NaN       599.0               0.0            0.0              NaN          NaN              1.0  0.004877           0.0          NaN\n",
      "39098    0.195164   0.250390         0.139938            NaN              NaN       598.0               0.0            0.0              NaN          NaN              1.0  0.004869           0.0          NaN\n",
      "39107    0.195164   0.250390         0.139938            NaN              NaN       598.0               0.0            0.0              NaN          NaN              1.0  0.004869           0.0          NaN\n",
      "65615    0.195163   0.250388         0.139938            NaN              NaN       596.0               0.0            0.0              NaN          NaN              1.0  0.004853           0.0          NaN\n",
      "40944    0.195163   0.250388         0.139938            NaN              NaN       595.0               0.0            0.0              NaN          NaN              1.0  0.004845           0.0          NaN\n",
      "26566    0.194974   0.250358         0.139590            NaN              NaN       550.0               0.0            0.0              NaN          NaN              1.0  0.004478           0.0          NaN\n",
      "04775    0.194973   0.250357         0.139590            NaN              NaN       548.0               0.0            0.0              NaN          NaN              1.0  0.004462           0.0          NaN\n",
      "26578    0.194884   0.250354         0.139413            NaN              NaN       544.0               0.0            0.0              NaN          NaN              1.0  0.004429           0.0          NaN\n",
      "72018    0.194882   0.250352         0.139413            NaN              NaN       540.0               0.0            0.0              NaN          NaN              1.0  0.004397           0.0          NaN\n",
      "[20:38:44 +  1.98s] âœ“ Finalize outputs done in 0.18s\n",
      "[20:38:44 +  1.98s] All done. ðŸš€\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IFAE (Income-Health-Access Equity) ZIP/ZCTA Ranking â€” Notebook Version\n",
    "# -----------------------------------------------------------------------------\n",
    "# Inputs (all CSVs; robust loaders handle small format differences):\n",
    "#   FINANCIAL_CSV  -> needs: NAME (ZCTA/ZIP name or code), S1901_C01_012E (median HH income)\n",
    "#   HEALTH_CSV     -> needs: ZCTA5 (5-digit), GHLTH_CrudePrev (general poor health %)\n",
    "#   PHARMACY_CSV   -> needs: ZIP (5-digit), NAME (pharmacy name), X, Y (coords; optional)\n",
    "#   POPULATION_CSV -> teammate used skiprows=10; script will autodetect 3 useful cols:\n",
    "#                     ZCTA/ZIP code, population, and optionally land area (km2 or mi2)\n",
    "#\n",
    "# Outputs:\n",
    "#   results/national_ifae_rank.csv\n",
    "#   results/top5_ifae.csv\n",
    "#\n",
    "# Method:\n",
    "#   - Build features by ZCTA/ZIP: median income, poor health %, population,\n",
    "#     pharmacies per 10k population (as access proxy), and (if available) density\n",
    "#   - Normalize features (0..1), form a transparent composite, and also fit\n",
    "#     an IsolationForest on the feature vector. Final IFAE score = 0.5*composite +\n",
    "#     0.5*iforest_anomaly (higher => more underserved / priority).\n",
    "#\n",
    "# Dependencies: pandas, numpy, scikit-learn (IsolationForest); pyarrow optional.\n",
    "# =============================================================================\n",
    "\n",
    "import os, time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# === CONFIG: set your file paths here ===\n",
    "FINANCIAL_CSV  = \"data/financial_data.csv\"     # needs: NAME, S1901_C01_012E\n",
    "HEALTH_CSV     = \"data/health_data.csv\"        # needs: ZCTA5, GHLTH_CrudePrev\n",
    "PHARMACY_CSV   = \"data/pharmacy_data.csv\"      # needs: ZIP, NAME, X, Y\n",
    "POPULATION_CSV = \"data/population_data.csv\"    # your teammate used skiprows=10; 3 useful cols\n",
    "\n",
    "OUT_DIR        = \"results\"                     # outputs: national_ifae_rank.csv, top5_ifae.csv\n",
    "CONTAMINATION  = 0.03                          # IsolationForest sensitivity (try 0.02â€“0.05)\n",
    "TOP_K          = 10\n",
    "\n",
    "# ---------- Monitoring helpers ----------\n",
    "_T0 = time.time()\n",
    "def stamp(msg):\n",
    "    now = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(f\"[{now} +{time.time()-_T0:6.2f}s] {msg}\", flush=True)\n",
    "\n",
    "class Step:\n",
    "    def __init__(self, name): self.name=name; self.t0=None\n",
    "    def __enter__(self): self.t0=time.time(); stamp(f\"â–¶ {self.name} ...\"); return self\n",
    "    def __exit__(self, et, ev, tb):\n",
    "        dt = time.time()-self.t0\n",
    "        stamp((\"âœ“ \" if et is None else \"âœ– \") + f\"{self.name} {'done' if et is None else 'failed'} in {dt:.2f}s\")\n",
    "\n",
    "def read_csv_smart(path, **kw):\n",
    "    p = Path(path)\n",
    "    if not p.exists(): raise FileNotFoundError(f\"Missing file: {path}\")\n",
    "    try:\n",
    "        return pd.read_csv(path, low_memory=False, **kw)\n",
    "    except Exception as e:\n",
    "        stamp(f\"CSV read warning: {e}. Retrying with simpler defaults.\")\n",
    "        return pd.read_csv(path)\n",
    "\n",
    "def minmax(s):\n",
    "    x = pd.to_numeric(s, errors='coerce')\n",
    "    mn, mx = x.min(skipna=True), x.max(skipna=True)\n",
    "    if np.isnan(mn) or np.isnan(mx) or mx==mn:\n",
    "        return pd.Series(0.0, index=x.index)\n",
    "    return (x - mn) / (mx - mn)\n",
    "\n",
    "def coerce_zcta(series):\n",
    "    \"\"\"Return 5-digit, zero-padded strings; strips non-digit chars if present.\"\"\"\n",
    "    s = series.astype(str).str.extract(r\"(\\d{3,5})\", expand=False)\n",
    "    return s.fillna(\"\").str.zfill(5)\n",
    "\n",
    "# ---------- Load & prepare each source ----------\n",
    "with Step(\"Load FINANCIAL (income)\"):\n",
    "    fin = read_csv_smart(FINANCIAL_CSV)\n",
    "    # Try to identify ZCTA code\n",
    "    zcta_col = None\n",
    "    for cand in [\"ZCTA5\",\"zcta5\",\"ZCTA\",\"zcta\",\"ZIP\",\"Zip\",\"NAME\",\"Name\",\"name\"]:\n",
    "        if cand in fin.columns:\n",
    "            zcta_col = cand; break\n",
    "    if zcta_col is None:\n",
    "        raise KeyError(f\"Could not find a ZCTA/ZIP column in {FINANCIAL_CSV}. Columns: {list(fin.columns)[:10]} ...\")\n",
    "    if \"S1901_C01_012E\" not in fin.columns:\n",
    "        raise KeyError(\"Missing S1901_C01_012E (median HH income) in FINANCIAL_CSV.\")\n",
    "    fin = fin.rename(columns={zcta_col:\"ZCTA5\"})\n",
    "    fin[\"ZCTA5\"] = coerce_zcta(fin[\"ZCTA5\"])\n",
    "    fin = fin[[\"ZCTA5\",\"S1901_C01_012E\"]].copy()\n",
    "    fin[\"S1901_C01_012E\"] = pd.to_numeric(fin[\"S1901_C01_012E\"], errors=\"coerce\")\n",
    "    stamp(f\"FIN rows={len(fin)}, null income={fin['S1901_C01_012E'].isna().sum()}\")\n",
    "\n",
    "with Step(\"Load HEALTH (poor general health %)\"):\n",
    "    hlth = read_csv_smart(HEALTH_CSV)\n",
    "    if \"ZCTA5\" not in hlth.columns:\n",
    "        # attempt alias\n",
    "        for cand in [\"ZCTA\",\"zcta\",\"ZIP\",\"Zip\",\"name\",\"NAME\"]:\n",
    "            if cand in hlth.columns:\n",
    "                hlth = hlth.rename(columns={cand:\"ZCTA5\"})\n",
    "                break\n",
    "    if \"ZCTA5\" not in hlth.columns or \"GHLTH_CrudePrev\" not in hlth.columns:\n",
    "        raise KeyError(\"HEALTH_CSV must contain ZCTA5 and GHLTH_CrudePrev.\")\n",
    "    hlth[\"ZCTA5\"] = coerce_zcta(hlth[\"ZCTA5\"])\n",
    "    hlth[\"GHLTH_CrudePrev\"] = pd.to_numeric(hlth[\"GHLTH_CrudePrev\"], errors=\"coerce\")\n",
    "    hlth = hlth[[\"ZCTA5\",\"GHLTH_CrudePrev\"]]\n",
    "    stamp(f\"HEALTH rows={len(hlth)}, null health%={hlth['GHLTH_CrudePrev'].isna().sum()}\")\n",
    "\n",
    "with Step(\"Load PHARMACY (access proxy)\"):\n",
    "    ph = read_csv_smart(PHARMACY_CSV)\n",
    "    for needed in [\"ZIP\",\"NAME\"]:\n",
    "        if needed not in ph.columns:\n",
    "            raise KeyError(f\"PHARMACY_CSV must contain {needed}.\")\n",
    "    ph[\"ZCTA5\"] = coerce_zcta(ph[\"ZIP\"])\n",
    "    # count unique pharmacies per ZCTA\n",
    "    ph_cnt = ph.groupby(\"ZCTA5\", dropna=False)[\"NAME\"].nunique(dropna=True).reset_index()\n",
    "    ph_cnt = ph_cnt.rename(columns={\"NAME\":\"pharmacies_count\"})\n",
    "    stamp(f\"PHARMACY unique ZCTA5={ph_cnt['ZCTA5'].nunique()}, total pharmacies={ph_cnt['pharmacies_count'].sum()}\")\n",
    "\n",
    "with Step(\"Load POPULATION (skiprows=10 heuristic + autodetect)\"):\n",
    "    pop = read_csv_smart(POPULATION_CSV, skiprows=10)\n",
    "    # try to identify code + population + (optional) land area\n",
    "    code_col = None\n",
    "    for cand in [\"ZCTA5\",\"ZCTA\",\"ZIP\",\"Zip\",\"GEOID\",\"geoid\",\"NAME\",\"name\"]:\n",
    "        if cand in pop.columns:\n",
    "            code_col=cand; break\n",
    "    if code_col is None:\n",
    "        # fallback: choose first object-like column\n",
    "        obj_cols = [c for c in pop.columns if pop[c].dtype == object]\n",
    "        code_col = obj_cols[0] if obj_cols else pop.columns[0]\n",
    "    pop = pop.rename(columns={code_col:\"ZCTA5\"})\n",
    "    pop[\"ZCTA5\"] = coerce_zcta(pop[\"ZCTA5\"])\n",
    "\n",
    "    # population column guess\n",
    "    pop_col = None\n",
    "    for cand in [\"POP\",\"Population\",\"population\",\"TOTAL_POP\",\"TotPop\",\"DP05_0001E\",\"pop\"]:\n",
    "        if cand in pop.columns:\n",
    "            pop_col=cand; break\n",
    "    if pop_col is None:\n",
    "        # choose the largest-sum numeric column as population\n",
    "        num_cols = [c for c in pop.columns if pd.api.types.is_numeric_dtype(pop[c])]\n",
    "        sums = {c: pd.to_numeric(pop[c], errors=\"coerce\").sum(skipna=True) for c in num_cols}\n",
    "        pop_col = max(sums, key=sums.get) if sums else None\n",
    "    if pop_col is None:\n",
    "        raise KeyError(\"Could not infer population column in POPULATION_CSV.\")\n",
    "\n",
    "    # optional land area\n",
    "    land_col = None\n",
    "    for cand in [\"land_area_km2\",\"Land_Area_km2\",\"ALAND_KM2\",\"aland_km2\",\"ALAND\",\"area\",\"AREA_KM2\",\"ALAND_SQMI\",\"AREALAND\"]:\n",
    "        if cand in pop.columns:\n",
    "            land_col = cand; break\n",
    "\n",
    "    keep_cols = [\"ZCTA5\", pop_col] + ([land_col] if land_col else [])\n",
    "    pop = pop[keep_cols].copy()\n",
    "    pop = pop.rename(columns={pop_col:\"population\"})\n",
    "    pop[\"population\"] = pd.to_numeric(pop[\"population\"], errors=\"coerce\")\n",
    "    if land_col:\n",
    "        pop = pop.rename(columns={land_col:\"land_area_raw\"})\n",
    "        pop[\"land_area_raw\"] = pd.to_numeric(pop[\"land_area_raw\"], errors=\"coerce\")\n",
    "\n",
    "    stamp(f\"POP rows={len(pop)}, null pop={pop['population'].isna().sum()}, land_col={land_col}\")\n",
    "\n",
    "# ---------- Merge to ZCTA frame ----------\n",
    "with Step(\"Merge all features by ZCTA/ZIP\"):\n",
    "    df = fin.merge(hlth, on=\"ZCTA5\", how=\"outer\") \\\n",
    "            .merge(pop, on=\"ZCTA5\", how=\"outer\") \\\n",
    "            .merge(ph_cnt, on=\"ZCTA5\", how=\"left\")\n",
    "    stamp(f\"Merged shape: {df.shape}\")\n",
    "    print(\"Top null counts:\\n\", df.isna().sum().sort_values(ascending=False).head(10).to_string(), flush=True)\n",
    "\n",
    "# ---------- Feature engineering ----------\n",
    "with Step(\"Feature engineering\"):\n",
    "    # income\n",
    "    df[\"median_income\"] = pd.to_numeric(df[\"S1901_C01_012E\"], errors=\"coerce\")\n",
    "    # health burden\n",
    "    df[\"poor_health_pct\"] = pd.to_numeric(df[\"GHLTH_CrudePrev\"], errors=\"coerce\")\n",
    "    # access proxy\n",
    "    df[\"pharmacies_count\"] = pd.to_numeric(df[\"pharmacies_count\"], errors=\"coerce\").fillna(0)\n",
    "    # pharmacies per 10k (guard against div by zero)\n",
    "    df[\"pharm_per_10k\"] = np.where(df[\"population\"].gt(0),\n",
    "                                   1e4 * df[\"pharmacies_count\"] / df[\"population\"],\n",
    "                                   np.nan)\n",
    "    # population density if land provided; try to detect units:\n",
    "    if \"land_area_raw\" in df.columns:\n",
    "        # If raw area looks like square meters (ALAND), convert to km2\n",
    "        # Heuristic: median ~10^6â€“10^9 for sq meters; <1e4 for km2\n",
    "        med_area = np.nanmedian(df[\"land_area_raw\"])\n",
    "        if np.isfinite(med_area) and med_area > 1e5:\n",
    "            df[\"land_area_km2\"] = df[\"land_area_raw\"] / 1e6\n",
    "        else:\n",
    "            df[\"land_area_km2\"] = df[\"land_area_raw\"]\n",
    "        df[\"pop_density\"] = np.where(df[\"land_area_km2\"].gt(0),\n",
    "                                     df[\"population\"] / df[\"land_area_km2\"],\n",
    "                                     np.nan)\n",
    "    else:\n",
    "        df[\"pop_density\"] = np.nan\n",
    "\n",
    "    # Normalizations\n",
    "    df[\"income_norm_inv\"]   = 1.0 - minmax(df[\"median_income\"])         # lower income -> higher need\n",
    "    df[\"health_norm\"]       = minmax(df[\"poor_health_pct\"])             # higher poor-health% -> higher need\n",
    "    df[\"access_norm_inv\"]   = 1.0 - minmax(df[\"pharm_per_10k\"])         # fewer pharmacies/10k -> higher need\n",
    "    df[\"pop_norm\"]          = minmax(df[\"population\"])                  # prioritize where more people\n",
    "    df[\"density_norm\"]      = minmax(df[\"pop_density\"])                 # optional\n",
    "\n",
    "    for col in [\"median_income\",\"poor_health_pct\",\"pharm_per_10k\",\"population\",\"pop_density\"]:\n",
    "        if col in df.columns:\n",
    "            x = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "            stamp(f\"Range {col}: min={np.nanmin(x):.3f} max={np.nanmax(x):.3f} NaN={np.isnan(x).sum()}\")\n",
    "\n",
    "# ---------- Composite score ----------\n",
    "with Step(\"Compute composite & train IsolationForest\"):\n",
    "    # Transparent composite (tweakable weights)\n",
    "    w_income, w_health, w_access, w_pop, w_density = 0.30, 0.35, 0.25, 0.08, 0.02\n",
    "    df[\"composite\"] = (\n",
    "        w_income  * df[\"income_norm_inv\"].fillna(0) +\n",
    "        w_health  * df[\"health_norm\"].fillna(0) +\n",
    "        w_access  * df[\"access_norm_inv\"].fillna(0) +\n",
    "        w_pop     * df[\"pop_norm\"].fillna(0) +\n",
    "        w_density * df[\"density_norm\"].fillna(0)\n",
    "    )\n",
    "\n",
    "    # IsolationForest on normalized features\n",
    "    feats = df[[\"income_norm_inv\",\"health_norm\",\"access_norm_inv\",\"pop_norm\",\"density_norm\"]].fillna(0.0).values\n",
    "    iforest = IsolationForest(random_state=42, contamination=CONTAMINATION, n_estimators=300)\n",
    "    iforest.fit(feats)\n",
    "    # decision_function: higher is less anomalous; we want higher = more underserved,\n",
    "    # so invert and min-max\n",
    "    decision = iforest.decision_function(feats)  # larger -> more normal\n",
    "    inv = -decision\n",
    "    # scale to 0..1\n",
    "    inv = (inv - inv.min()) / (inv.max() - inv.min() + 1e-12)\n",
    "    df[\"iforest_anomaly\"] = inv\n",
    "\n",
    "    # Final IFAE score = blend\n",
    "    df[\"IFAE_score\"] = 0.5 * df[\"composite\"] + 0.5 * df[\"iforest_anomaly\"]\n",
    "\n",
    "with Step(\"Finalize outputs\"):\n",
    "    out = Path(OUT_DIR); out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Prepare nice columns\n",
    "    keep = [\n",
    "        \"ZCTA5\",\"IFAE_score\",\"composite\",\"iforest_anomaly\",\n",
    "        \"median_income\",\"poor_health_pct\",\"population\",\"pharmacies_count\",\"pharm_per_10k\",\n",
    "        \"income_norm_inv\",\"health_norm\",\"access_norm_inv\",\"pop_norm\",\"density_norm\",\"pop_density\"\n",
    "    ]\n",
    "    keep = [c for c in keep if c in df.columns]\n",
    "    ranked = df[keep].copy()\n",
    "    ranked = ranked.sort_values(\"IFAE_score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Write full national ranking & top-k\n",
    "    national_path = out / \"national_ifae_rank.csv\"\n",
    "    topk_path     = out / \"top5_ifae.csv\"\n",
    "    ranked.to_csv(national_path, index=False)\n",
    "    ranked.tail(TOP_K).to_csv(topk_path, index=False)\n",
    "\n",
    "    stamp(f\"Wrote {national_path}\")\n",
    "    stamp(f\"Wrote {topk_path}\")\n",
    "    print(\"\\nTop 5 preview:\\n\", ranked.tail(TOP_K).to_string(index=False))\n",
    "\n",
    "stamp(\"All done. ðŸš€\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "915074c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:30:35 +  0.00s] â–¶ Load FINANCIAL (income) ...\n",
      "[20:30:35 +  0.29s] FIN rows=33773, null income=3264\n",
      "[20:30:35 +  0.29s] âœ“ Load FINANCIAL (income) done in 0.29s\n",
      "[20:30:35 +  0.29s] â–¶ Load HEALTH (poor general health %) ...\n",
      "[20:30:35 +  0.48s] HEALTH rows=32520, null health%=0\n",
      "[20:30:35 +  0.48s] âœ“ Load HEALTH (poor general health %) done in 0.19s\n",
      "[20:30:35 +  0.48s] â–¶ Load PHARMACY (access proxy) ...\n",
      "[20:30:36 +  0.94s] PHARMACY unique ZCTA5=14940, total pharmacies=61970\n",
      "[20:30:36 +  0.94s] âœ“ Load PHARMACY (access proxy) done in 0.47s\n",
      "[20:30:36 +  0.94s] â–¶ Load POPULATION (skiprows=10 heuristic + autodetect) ...\n",
      "[20:30:36 +  0.99s] POP rows=40959, null pop=0, land_col=None\n",
      "[20:30:36 +  0.99s] âœ“ Load POPULATION (skiprows=10 heuristic + autodetect) done in 0.05s\n",
      "[20:30:36 +  0.99s] â–¶ Merge all features by ZCTA/ZIP ...\n",
      "[20:30:36 +  1.03s] Merged shape: (41094, 5)\n",
      "Top null counts:\n",
      " pharmacies_count    26171\n",
      "S1901_C01_012E      10585\n",
      "GHLTH_CrudePrev      8574\n",
      "population            135\n",
      "ZCTA5                   0\n",
      "[20:30:36 +  1.03s] âœ“ Merge all features by ZCTA/ZIP done in 0.04s\n",
      "[20:30:36 +  1.03s] â–¶ Feature engineering ...\n",
      "[20:30:36 +  1.03s] Range median_income: min=6229.000 max=249688.000 NaN=10585\n",
      "[20:30:36 +  1.03s] Range poor_health_pct: min=3.600 max=56.500 NaN=8574\n",
      "[20:30:36 +  1.03s] Range pharm_per_10k: min=0.000 max=2000.000 NaN=1064\n",
      "[20:30:36 +  1.03s] Range population: min=0.000 max=122814.000 NaN=135\n",
      "[20:30:36 +  1.03s] Range pop_density: min=nan max=nan NaN=41094\n",
      "[20:30:36 +  1.03s] âœ“ Feature engineering done in 0.01s\n",
      "[20:30:36 +  1.04s] â–¶ Compute composite & train IsolationForest ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/5gzqwh3d5sx43n9fsy97czyc0000gn/T/ipykernel_54177/2454373550.py:210: RuntimeWarning: All-NaN axis encountered\n",
      "  stamp(f\"Range {col}: min={np.nanmin(x):.3f} max={np.nanmax(x):.3f} NaN={np.isnan(x).sum()}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:30:36 +  1.71s] âœ“ Compute composite & train IsolationForest done in 0.68s\n",
      "[20:30:36 +  1.71s] â–¶ Finalize outputs ...\n",
      "[20:30:37 +  1.89s] Wrote results/national_ifae_rank.csv\n",
      "[20:30:37 +  1.89s] Wrote results/top5_ifae.csv\n",
      "\n",
      "Top 5 preview:\n",
      " ZCTA5  IFAE_score  composite  iforest_anomaly  median_income  poor_health_pct  population  pharmacies_count  pharm_per_10k  income_norm_inv  health_norm  access_norm_inv  pop_norm  density_norm  pop_density\n",
      "78521    0.851494   0.812017         0.890971        41276.0             40.7     92108.0              19.0       2.062796         0.856046     0.701323         0.998969  0.749980           0.0          NaN\n",
      "90011    0.830166   0.786260         0.874073        53781.0             37.4    109414.0               4.0       0.365584         0.804682     0.638941         0.999817  0.890892           0.0          NaN\n",
      "78207    0.817008   0.816558         0.817458        30655.0             43.1     54601.0              11.0       2.014615         0.899671     0.746692         0.998993  0.444583           0.0          NaN\n",
      "06702    0.812677   0.826915         0.798440        16198.0             47.2      3025.0               3.0       9.917355         0.959053     0.824197         0.995041  0.024631           0.0          NaN\n",
      "10456    0.809243   0.781977         0.836509        35676.0             34.9     94218.0              15.0       1.592052         0.879047     0.591682         0.999204  0.767160           0.0          NaN\n",
      "10453    0.799910   0.765305         0.834516        35482.0             33.8     79606.0              20.0       2.512373         0.879844     0.570888         0.998744  0.648183           0.0          NaN\n",
      "79901    0.794613   0.885554         0.703672        13984.0             54.8     10138.0               2.0       1.972776         0.968147     0.967864         0.999014  0.082548           0.0          NaN\n",
      "90201    0.791579   0.765303         0.817855        56824.0             35.5    102433.0              11.0       1.073873         0.792183     0.603025         0.999463  0.834050           0.0          NaN\n",
      "41643    0.790424   0.736258         0.844589        24310.0             37.7        73.0               1.0     136.986301         0.925733     0.644612         0.931507  0.000594           0.0          NaN\n",
      "77036    0.789899   0.770438         0.809359        43853.0             36.4     76831.0              16.0       2.082493         0.845461     0.620038         0.998959  0.625588           0.0          NaN\n",
      "[20:30:37 +  1.89s] âœ“ Finalize outputs done in 0.18s\n",
      "[20:30:37 +  1.89s] All done. ðŸš€\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# IFAE (Income-Health-Access Equity) ZIP/ZCTA Ranking â€” Notebook Version\n",
    "# -----------------------------------------------------------------------------\n",
    "# Inputs (all CSVs; robust loaders handle small format differences):\n",
    "#   FINANCIAL_CSV  -> needs: NAME (ZCTA/ZIP name or code), S1901_C01_012E (median HH income)\n",
    "#   HEALTH_CSV     -> needs: ZCTA5 (5-digit), GHLTH_CrudePrev (general poor health %)\n",
    "#   PHARMACY_CSV   -> needs: ZIP (5-digit), NAME (pharmacy name), X, Y (coords; optional)\n",
    "#   POPULATION_CSV -> teammate used skiprows=10; script will autodetect 3 useful cols:\n",
    "#                     ZCTA/ZIP code, population, and optionally land area (km2 or mi2)\n",
    "#\n",
    "# Outputs:\n",
    "#   results/national_ifae_rank.csv\n",
    "#   results/top5_ifae.csv\n",
    "#\n",
    "# Method:\n",
    "#   - Build features by ZCTA/ZIP: median income, poor health %, population,\n",
    "#     pharmacies per 10k population (as access proxy), and (if available) density\n",
    "#   - Normalize features (0..1), form a transparent composite, and also fit\n",
    "#     an IsolationForest on the feature vector. Final IFAE score = 0.5*composite +\n",
    "#     0.5*iforest_anomaly (higher => more underserved / priority).\n",
    "#\n",
    "# Dependencies: pandas, numpy, scikit-learn (IsolationForest); pyarrow optional.\n",
    "# =============================================================================\n",
    "\n",
    "import os, time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# === CONFIG: set your file paths here ===\n",
    "FINANCIAL_CSV  = \"data/financial_data.csv\"     # needs: NAME, S1901_C01_012E\n",
    "HEALTH_CSV     = \"data/health_data.csv\"        # needs: ZCTA5, GHLTH_CrudePrev\n",
    "PHARMACY_CSV   = \"data/pharmacy_data.csv\"      # needs: ZIP, NAME, X, Y\n",
    "POPULATION_CSV = \"data/population_data.csv\"    # your teammate used skiprows=10; 3 useful cols\n",
    "\n",
    "OUT_DIR        = \"results\"                     # outputs: national_ifae_rank.csv, top5_ifae.csv\n",
    "CONTAMINATION  = 0.03                          # IsolationForest sensitivity (try 0.02â€“0.05)\n",
    "TOP_K          = 10\n",
    "\n",
    "# ---------- Monitoring helpers ----------\n",
    "_T0 = time.time()\n",
    "def stamp(msg):\n",
    "    now = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(f\"[{now} +{time.time()-_T0:6.2f}s] {msg}\", flush=True)\n",
    "\n",
    "class Step:\n",
    "    def __init__(self, name): self.name=name; self.t0=None\n",
    "    def __enter__(self): self.t0=time.time(); stamp(f\"â–¶ {self.name} ...\"); return self\n",
    "    def __exit__(self, et, ev, tb):\n",
    "        dt = time.time()-self.t0\n",
    "        stamp((\"âœ“ \" if et is None else \"âœ– \") + f\"{self.name} {'done' if et is None else 'failed'} in {dt:.2f}s\")\n",
    "\n",
    "def read_csv_smart(path, **kw):\n",
    "    p = Path(path)\n",
    "    if not p.exists(): raise FileNotFoundError(f\"Missing file: {path}\")\n",
    "    try:\n",
    "        return pd.read_csv(path, low_memory=False, **kw)\n",
    "    except Exception as e:\n",
    "        stamp(f\"CSV read warning: {e}. Retrying with simpler defaults.\")\n",
    "        return pd.read_csv(path)\n",
    "\n",
    "def minmax(s):\n",
    "    x = pd.to_numeric(s, errors='coerce')\n",
    "    mn, mx = x.min(skipna=True), x.max(skipna=True)\n",
    "    if np.isnan(mn) or np.isnan(mx) or mx==mn:\n",
    "        return pd.Series(0.0, index=x.index)\n",
    "    return (x - mn) / (mx - mn)\n",
    "\n",
    "def coerce_zcta(series):\n",
    "    \"\"\"Return 5-digit, zero-padded strings; strips non-digit chars if present.\"\"\"\n",
    "    s = series.astype(str).str.extract(r\"(\\d{3,5})\", expand=False)\n",
    "    return s.fillna(\"\").str.zfill(5)\n",
    "\n",
    "# ---------- Load & prepare each source ----------\n",
    "with Step(\"Load FINANCIAL (income)\"):\n",
    "    fin = read_csv_smart(FINANCIAL_CSV)\n",
    "    # Try to identify ZCTA code\n",
    "    zcta_col = None\n",
    "    for cand in [\"ZCTA5\",\"zcta5\",\"ZCTA\",\"zcta\",\"ZIP\",\"Zip\",\"NAME\",\"Name\",\"name\"]:\n",
    "        if cand in fin.columns:\n",
    "            zcta_col = cand; break\n",
    "    if zcta_col is None:\n",
    "        raise KeyError(f\"Could not find a ZCTA/ZIP column in {FINANCIAL_CSV}. Columns: {list(fin.columns)[:10]} ...\")\n",
    "    if \"S1901_C01_012E\" not in fin.columns:\n",
    "        raise KeyError(\"Missing S1901_C01_012E (median HH income) in FINANCIAL_CSV.\")\n",
    "    fin = fin.rename(columns={zcta_col:\"ZCTA5\"})\n",
    "    fin[\"ZCTA5\"] = coerce_zcta(fin[\"ZCTA5\"])\n",
    "    fin = fin[[\"ZCTA5\",\"S1901_C01_012E\"]].copy()\n",
    "    fin[\"S1901_C01_012E\"] = pd.to_numeric(fin[\"S1901_C01_012E\"], errors=\"coerce\")\n",
    "    stamp(f\"FIN rows={len(fin)}, null income={fin['S1901_C01_012E'].isna().sum()}\")\n",
    "\n",
    "with Step(\"Load HEALTH (poor general health %)\"):\n",
    "    hlth = read_csv_smart(HEALTH_CSV)\n",
    "    if \"ZCTA5\" not in hlth.columns:\n",
    "        # attempt alias\n",
    "        for cand in [\"ZCTA\",\"zcta\",\"ZIP\",\"Zip\",\"name\",\"NAME\"]:\n",
    "            if cand in hlth.columns:\n",
    "                hlth = hlth.rename(columns={cand:\"ZCTA5\"})\n",
    "                break\n",
    "    if \"ZCTA5\" not in hlth.columns or \"GHLTH_CrudePrev\" not in hlth.columns:\n",
    "        raise KeyError(\"HEALTH_CSV must contain ZCTA5 and GHLTH_CrudePrev.\")\n",
    "    hlth[\"ZCTA5\"] = coerce_zcta(hlth[\"ZCTA5\"])\n",
    "    hlth[\"GHLTH_CrudePrev\"] = pd.to_numeric(hlth[\"GHLTH_CrudePrev\"], errors=\"coerce\")\n",
    "    hlth = hlth[[\"ZCTA5\",\"GHLTH_CrudePrev\"]]\n",
    "    stamp(f\"HEALTH rows={len(hlth)}, null health%={hlth['GHLTH_CrudePrev'].isna().sum()}\")\n",
    "\n",
    "with Step(\"Load PHARMACY (access proxy)\"):\n",
    "    ph = read_csv_smart(PHARMACY_CSV)\n",
    "    for needed in [\"ZIP\",\"NAME\"]:\n",
    "        if needed not in ph.columns:\n",
    "            raise KeyError(f\"PHARMACY_CSV must contain {needed}.\")\n",
    "    ph[\"ZCTA5\"] = coerce_zcta(ph[\"ZIP\"])\n",
    "    # count unique pharmacies per ZCTA\n",
    "    ph_cnt = ph.groupby(\"ZCTA5\", dropna=False)[\"NAME\"].nunique(dropna=True).reset_index()\n",
    "    ph_cnt = ph_cnt.rename(columns={\"NAME\":\"pharmacies_count\"})\n",
    "    stamp(f\"PHARMACY unique ZCTA5={ph_cnt['ZCTA5'].nunique()}, total pharmacies={ph_cnt['pharmacies_count'].sum()}\")\n",
    "\n",
    "with Step(\"Load POPULATION (skiprows=10 heuristic + autodetect)\"):\n",
    "    pop = read_csv_smart(POPULATION_CSV, skiprows=10)\n",
    "    # try to identify code + population + (optional) land area\n",
    "    code_col = None\n",
    "    for cand in [\"ZCTA5\",\"ZCTA\",\"ZIP\",\"Zip\",\"GEOID\",\"geoid\",\"NAME\",\"name\"]:\n",
    "        if cand in pop.columns:\n",
    "            code_col=cand; break\n",
    "    if code_col is None:\n",
    "        # fallback: choose first object-like column\n",
    "        obj_cols = [c for c in pop.columns if pop[c].dtype == object]\n",
    "        code_col = obj_cols[0] if obj_cols else pop.columns[0]\n",
    "    pop = pop.rename(columns={code_col:\"ZCTA5\"})\n",
    "    pop[\"ZCTA5\"] = coerce_zcta(pop[\"ZCTA5\"])\n",
    "\n",
    "    # population column guess\n",
    "    pop_col = None\n",
    "    for cand in [\"POP\",\"Population\",\"population\",\"TOTAL_POP\",\"TotPop\",\"DP05_0001E\",\"pop\"]:\n",
    "        if cand in pop.columns:\n",
    "            pop_col=cand; break\n",
    "    if pop_col is None:\n",
    "        # choose the largest-sum numeric column as population\n",
    "        num_cols = [c for c in pop.columns if pd.api.types.is_numeric_dtype(pop[c])]\n",
    "        sums = {c: pd.to_numeric(pop[c], errors=\"coerce\").sum(skipna=True) for c in num_cols}\n",
    "        pop_col = max(sums, key=sums.get) if sums else None\n",
    "    if pop_col is None:\n",
    "        raise KeyError(\"Could not infer population column in POPULATION_CSV.\")\n",
    "\n",
    "    # optional land area\n",
    "    land_col = None\n",
    "    for cand in [\"land_area_km2\",\"Land_Area_km2\",\"ALAND_KM2\",\"aland_km2\",\"ALAND\",\"area\",\"AREA_KM2\",\"ALAND_SQMI\",\"AREALAND\"]:\n",
    "        if cand in pop.columns:\n",
    "            land_col = cand; break\n",
    "\n",
    "    keep_cols = [\"ZCTA5\", pop_col] + ([land_col] if land_col else [])\n",
    "    pop = pop[keep_cols].copy()\n",
    "    pop = pop.rename(columns={pop_col:\"population\"})\n",
    "    pop[\"population\"] = pd.to_numeric(pop[\"population\"], errors=\"coerce\")\n",
    "    if land_col:\n",
    "        pop = pop.rename(columns={land_col:\"land_area_raw\"})\n",
    "        pop[\"land_area_raw\"] = pd.to_numeric(pop[\"land_area_raw\"], errors=\"coerce\")\n",
    "\n",
    "    stamp(f\"POP rows={len(pop)}, null pop={pop['population'].isna().sum()}, land_col={land_col}\")\n",
    "\n",
    "# ---------- Merge to ZCTA frame ----------\n",
    "with Step(\"Merge all features by ZCTA/ZIP\"):\n",
    "    df = fin.merge(hlth, on=\"ZCTA5\", how=\"outer\") \\\n",
    "            .merge(pop, on=\"ZCTA5\", how=\"outer\") \\\n",
    "            .merge(ph_cnt, on=\"ZCTA5\", how=\"left\")\n",
    "    stamp(f\"Merged shape: {df.shape}\")\n",
    "    print(\"Top null counts:\\n\", df.isna().sum().sort_values(ascending=False).tail(10).to_string(), flush=True)\n",
    "\n",
    "# ---------- Feature engineering ----------\n",
    "with Step(\"Feature engineering\"):\n",
    "    # income\n",
    "    df[\"median_income\"] = pd.to_numeric(df[\"S1901_C01_012E\"], errors=\"coerce\")\n",
    "    # health burden\n",
    "    df[\"poor_health_pct\"] = pd.to_numeric(df[\"GHLTH_CrudePrev\"], errors=\"coerce\")\n",
    "    # access proxy\n",
    "    df[\"pharmacies_count\"] = pd.to_numeric(df[\"pharmacies_count\"], errors=\"coerce\").fillna(0)\n",
    "    # pharmacies per 10k (guard against div by zero)\n",
    "    df[\"pharm_per_10k\"] = np.where(df[\"population\"].gt(0),\n",
    "                                   1e4 * df[\"pharmacies_count\"] / df[\"population\"],\n",
    "                                   np.nan)\n",
    "    # population density if land provided; try to detect units:\n",
    "    if \"land_area_raw\" in df.columns:\n",
    "        # If raw area looks like square meters (ALAND), convert to km2\n",
    "        # Heuristic: median ~10^6â€“10^9 for sq meters; <1e4 for km2\n",
    "        med_area = np.nanmedian(df[\"land_area_raw\"])\n",
    "        if np.isfinite(med_area) and med_area > 1e5:\n",
    "            df[\"land_area_km2\"] = df[\"land_area_raw\"] / 1e6\n",
    "        else:\n",
    "            df[\"land_area_km2\"] = df[\"land_area_raw\"]\n",
    "        df[\"pop_density\"] = np.where(df[\"land_area_km2\"].gt(0),\n",
    "                                     df[\"population\"] / df[\"land_area_km2\"],\n",
    "                                     np.nan)\n",
    "    else:\n",
    "        df[\"pop_density\"] = np.nan\n",
    "\n",
    "    # Normalizations\n",
    "    df[\"income_norm_inv\"]   = 1.0 - minmax(df[\"median_income\"])         # lower income -> higher need\n",
    "    df[\"health_norm\"]       = minmax(df[\"poor_health_pct\"])             # higher poor-health% -> higher need\n",
    "    df[\"access_norm_inv\"]   = 1.0 - minmax(df[\"pharm_per_10k\"])         # fewer pharmacies/10k -> higher need\n",
    "    df[\"pop_norm\"]          = minmax(df[\"population\"])                  # prioritize where more people\n",
    "    df[\"density_norm\"]      = minmax(df[\"pop_density\"])                 # optional\n",
    "\n",
    "    for col in [\"median_income\",\"poor_health_pct\",\"pharm_per_10k\",\"population\",\"pop_density\"]:\n",
    "        if col in df.columns:\n",
    "            x = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "            stamp(f\"Range {col}: min={np.nanmin(x):.3f} max={np.nanmax(x):.3f} NaN={np.isnan(x).sum()}\")\n",
    "\n",
    "# ---------- Composite score ----------\n",
    "with Step(\"Compute composite & train IsolationForest\"):\n",
    "    # Transparent composite (tweakable weights)\n",
    "    w_income, w_health, w_access, w_pop, w_density = 0.30, 0.35, 0.25, 0.08, 0.02\n",
    "    df[\"composite\"] = (\n",
    "        w_income  * df[\"income_norm_inv\"].fillna(0) +\n",
    "        w_health  * df[\"health_norm\"].fillna(0) +\n",
    "        w_access  * df[\"access_norm_inv\"].fillna(0) +\n",
    "        w_pop     * df[\"pop_norm\"].fillna(0) +\n",
    "        w_density * df[\"density_norm\"].fillna(0)\n",
    "    )\n",
    "\n",
    "    # IsolationForest on normalized features\n",
    "    feats = df[[\"income_norm_inv\",\"health_norm\",\"access_norm_inv\",\"pop_norm\",\"density_norm\"]].fillna(0.0).values\n",
    "    iforest = IsolationForest(random_state=42, contamination=CONTAMINATION, n_estimators=300)\n",
    "    iforest.fit(feats)\n",
    "    # decision_function: higher is less anomalous; we want higher = more underserved,\n",
    "    # so invert and min-max\n",
    "    decision = iforest.decision_function(feats)  # larger -> more normal\n",
    "    inv = -decision\n",
    "    # scale to 0..1\n",
    "    inv = (inv - inv.min()) / (inv.max() - inv.min() + 1e-12)\n",
    "    df[\"iforest_anomaly\"] = inv\n",
    "\n",
    "    # Final IFAE score = blend\n",
    "    df[\"IFAE_score\"] = 0.5 * df[\"composite\"] + 0.5 * df[\"iforest_anomaly\"]\n",
    "\n",
    "with Step(\"Finalize outputs\"):\n",
    "    out = Path(OUT_DIR); out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Prepare nice columns\n",
    "    keep = [\n",
    "        \"ZCTA5\",\"IFAE_score\",\"composite\",\"iforest_anomaly\",\n",
    "        \"median_income\",\"poor_health_pct\",\"population\",\"pharmacies_count\",\"pharm_per_10k\",\n",
    "        \"income_norm_inv\",\"health_norm\",\"access_norm_inv\",\"pop_norm\",\"density_norm\",\"pop_density\"\n",
    "    ]\n",
    "    keep = [c for c in keep if c in df.columns]\n",
    "    ranked = df[keep].copy()\n",
    "    ranked = ranked.sort_values(\"IFAE_score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Write full national ranking & top-k\n",
    "    national_path = out / \"national_ifae_rank.csv\"\n",
    "    topk_path     = out / \"top5_ifae.csv\"\n",
    "    ranked.to_csv(national_path, index=False)\n",
    "    ranked.tail(TOP_K).to_csv(topk_path, index=False)\n",
    "\n",
    "    stamp(f\"Wrote {national_path}\")\n",
    "    stamp(f\"Wrote {topk_path}\")\n",
    "    print(\"\\nTop 5 preview:\\n\", ranked.head(TOP_K).to_string(index=False))\n",
    "\n",
    "stamp(\"All done. ðŸš€\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0db78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== CONFIG (edit paths as needed) =====================\n",
    "FINANCIAL_CSV  = \"data/financial_data.csv\"     # expects: NAME, S1901_C01_012E\n",
    "HEALTH_CSV     = \"data/health_data.csv\"        # expects: ZCTA5, GHLTH_CrudePrev\n",
    "PHARMACY_CSV   = \"data/pharmacy_data.csv\"      # expects: ZIP, NAME, X, Y\n",
    "POPULATION_CSV = \"data/population_data.csv\"    # teammate used skiprows=10 and cols [1,2,3]\n",
    "\n",
    "OUT_DIR        = \"results\"\n",
    "CONTAMINATION  = 0.03     # IsolationForest sensitivity (try 0.02â€“0.05)\n",
    "TOP_K          = 5        # how many top/bottom rows to show/save\n",
    "# =======================================================================\n",
    "\n",
    "import os, warnings, numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ---- Try TensorFlow (AE); if missing we'll use PCA fallback automatically ----\n",
    "TF_AVAILABLE = True\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "except Exception:\n",
    "    TF_AVAILABLE = False\n",
    "    warnings.warn(\"TensorFlow not found; using PCA reconstruction error instead of Autoencoder.\")\n",
    "\n",
    "# --------------------------- Utility functions ---------------------------\n",
    "\n",
    "def winsorize(s: pd.Series, lo=0.01, hi=0.99) -> pd.Series:\n",
    "    s = pd.to_numeric(s, errors='coerce')\n",
    "    a, b = s.quantile(lo), s.quantile(hi)\n",
    "    return s.clip(a, b)\n",
    "\n",
    "def pct_rank(s: pd.Series) -> pd.Series:\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    if s.nunique(dropna=True) <= 1:\n",
    "        return pd.Series(0.5, index=s.index)\n",
    "    return s.rank(pct=True, method='average')\n",
    "\n",
    "def nonint_fraction(x: pd.Series) -> float:\n",
    "    x = pd.to_numeric(x, errors='coerce')\n",
    "    return float((np.abs(x - np.round(x)) > 1e-9).mean())\n",
    "\n",
    "# ----------------------------- Readers (robust) -----------------------------\n",
    "\n",
    "def read_financial_data(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[['NAME', 'S1901_C01_012E']].copy()\n",
    "    df['zip'] = df['NAME'].astype(str).str.extract(r'(\\d{5})')\n",
    "    df['median_income'] = pd.to_numeric(df['S1901_C01_012E'], errors='coerce')\n",
    "    return df[['zip','median_income']].dropna(subset=['zip'])\n",
    "\n",
    "def read_health_data(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[['ZCTA5', 'GHLTH_CrudePrev']].copy()\n",
    "    df['zip'] = df['ZCTA5'].astype(str).str.split('.').str[0].str.zfill(5)\n",
    "    df['health_burden'] = pd.to_numeric(df['GHLTH_CrudePrev'], errors='coerce')\n",
    "    return df[['zip','health_burden']]\n",
    "\n",
    "def read_pharmacy_data(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[['ZIP', 'NAME', 'X', 'Y']].copy()\n",
    "    df['zip'] = df['ZIP'].astype(str).str.zfill(5)\n",
    "    counts = df.groupby('zip').size().reset_index(name='n_pharmacies')\n",
    "    # Approx centroid from points (biased where pharmacies exist; OK as fallback)\n",
    "    cent = df.groupby('zip')[['Y','X']].mean().rename(columns={'Y':'lat','X':'lon'}).reset_index()\n",
    "    out = counts.merge(cent, on='zip', how='left')\n",
    "    return out\n",
    "\n",
    "def read_population_data(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Tries to extract (zip, population, land_km2 OR pop_density).\n",
    "    We replicate your teammate pattern (skiprows=10; select cols [1,2,3]) and infer.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, skiprows=10)\n",
    "    sub = df.iloc[:, [1,2,3]].copy()\n",
    "    # detect ZCTA column\n",
    "    zcol = None\n",
    "    for c in sub.columns:\n",
    "        if sub[c].astype(str).str.match(r'^\\d{5}$').mean() > 0.4:\n",
    "            zcol = c; break\n",
    "    if zcol is None:\n",
    "        for c in sub.columns:\n",
    "            if sub[c].astype(str).str.contains(r'\\d{5}').mean() > 0.4:\n",
    "                zcol = c; break\n",
    "    if zcol is None:\n",
    "        zcol = sub.columns[0]\n",
    "    rem = [c for c in sub.columns if c != zcol]\n",
    "    a = pd.to_numeric(sub[rem[0]], errors='coerce')\n",
    "    b = pd.to_numeric(sub[rem[1]], errors='coerce')\n",
    "\n",
    "    # Heuristics:\n",
    "    # - population: mostly integers, often > 100\n",
    "    pop_like_a = ((a >= 50).mean() > 0.6) and ((np.abs(a - np.round(a)) < 1e-9).mean() > 0.5)\n",
    "    pop_like_b = ((b >= 50).mean() > 0.6) and ((np.abs(b - np.round(b)) < 1e-9).mean() > 0.5)\n",
    "\n",
    "    out = pd.DataFrame({'zip': sub[zcol].astype(str).str.extract(r'(\\d{5})')[0].str.zfill(5)})\n",
    "\n",
    "    population = None\n",
    "    land_km2 = None\n",
    "    pop_density = None\n",
    "\n",
    "    if pop_like_a and not pop_like_b:\n",
    "        population = a\n",
    "        other = b\n",
    "    elif pop_like_b and not pop_like_a:\n",
    "        population = b\n",
    "        other = a\n",
    "    else:\n",
    "        # neither looks like clean population; assume we're given a density-like column\n",
    "        other = a if nonint_fraction(a) >= nonint_fraction(b) else b\n",
    "\n",
    "    if population is not None:\n",
    "        out['population'] = population.round().astype('Int64')\n",
    "        # Try to infer land if the \"other\" looks huge (likely m^2) or reasonable (km^2)\n",
    "        if other.notna().sum() > 0:\n",
    "            med = other.median(skipna=True)\n",
    "            if pd.notna(med):\n",
    "                if med > 10000:        # probably m^2\n",
    "                    land_km2 = other / 1e6\n",
    "                else:\n",
    "                    land_km2 = other    # assume already km^2 or density-ish small number\n",
    "        if land_km2 is not None:\n",
    "            out['land_km2'] = land_km2\n",
    "            out['pop_density'] = out['population'] / out['land_km2'].replace(0, np.nan)\n",
    "    else:\n",
    "        # No population found; treat \"other\" as pop_density proxy\n",
    "        pop_density = other\n",
    "        out['pop_density'] = pop_density\n",
    "\n",
    "    return out.dropna(subset=['zip'])\n",
    "\n",
    "# ---------------------- Build master & engineered features ----------------------\n",
    "\n",
    "def build_master(fin_path, hl_path, pharm_path, pop_path) -> pd.DataFrame:\n",
    "    fin  = read_financial_data(fin_path)\n",
    "    hlth = read_health_data(hl_path)\n",
    "    pharm= read_pharmacy_data(pharm_path)\n",
    "    pop  = read_population_data(pop_path)\n",
    "\n",
    "    df = pharm.merge(fin, on='zip', how='outer') \\\n",
    "              .merge(hlth, on='zip', how='outer') \\\n",
    "              .merge(pop, on='zip', how='outer')\n",
    "\n",
    "    # Fill pharmacy counts\n",
    "    df['n_pharmacies'] = df['n_pharmacies'].fillna(0).astype(int)\n",
    "\n",
    "    # Winsorize raw continuous fields before percentiling\n",
    "    for c in ['median_income','health_burden','population','land_km2','pop_density']:\n",
    "        if c in df.columns:\n",
    "            df[c] = winsorize(df[c])\n",
    "\n",
    "    # ---- Scarcity (preferred): people per pharmacy + pharmacies per 10k ----\n",
    "    if 'population' in df.columns and df['population'].notna().any():\n",
    "        denom = df['n_pharmacies'].replace(0, 1)              # keep finite when 0 pharmacies\n",
    "        df['pop_per_pharmacy'] = df['population'] / denom\n",
    "        df['pharm_per_10k']    = 10000 * df['n_pharmacies'] / df['population'].replace(0, np.nan)\n",
    "        df['scarcity']         = df['pop_per_pharmacy']       # higher = worse\n",
    "    else:\n",
    "        # Fallback: density-based proxy (kept only if no population)\n",
    "        warnings.warn(\"Population not found; using density-based scarcity proxy.\")\n",
    "        eps = 1e-9\n",
    "        per_density = df['n_pharmacies'] / (pd.to_numeric(df['pop_density'], errors='coerce').fillna(0) + eps)\n",
    "        df['scarcity'] = 1.0 / (1.0 + per_density)\n",
    "\n",
    "    # ---- National percentiles ONLY (higher = worse) ----\n",
    "    df['scarcity_pct']    = pct_rank(df['scarcity'])\n",
    "    df['health_pct']      = pct_rank(df['health_burden'])\n",
    "    df['fin_stress_pct']  = 1 - pct_rank(df['median_income'])\n",
    "    if 'pop_density' in df.columns:\n",
    "        df['dens_pct']    = pct_rank(df['pop_density'])\n",
    "    else:\n",
    "        df['dens_pct']    = 0.5  # neutral if unknown\n",
    "\n",
    "    # ---- Transparent baseline (national percentiles) ----\n",
    "    feat_national = ['scarcity_pct','health_pct','fin_stress_pct','dens_pct']\n",
    "    df['baseline_score'] = df[feat_national].mean(axis=1)\n",
    "\n",
    "    # ---- Model matrix uses the SAME national percentiles (no state-relative) ----\n",
    "    Xdf = df[feat_national].fillna(0.5).astype(float)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(Xdf.values)\n",
    "\n",
    "    # ---- Isolation Forest ----\n",
    "    iso = IsolationForest(n_estimators=400, contamination=CONTAMINATION, random_state=7, n_jobs=-1).fit(X)\n",
    "    raw_if = -iso.score_samples(X)  # larger = more anomalous\n",
    "\n",
    "    # ---- Autoencoder (or PCA fallback) ----\n",
    "    if TF_AVAILABLE:\n",
    "        tf.random.set_seed(7)\n",
    "        D = X.shape[1]\n",
    "        ae = keras.Sequential([\n",
    "            keras.layers.Input(shape=(D,)),\n",
    "            keras.layers.Dense(16, activation='relu', kernel_regularizer=keras.regularizers.l2(1e-4)),\n",
    "            keras.layers.Dropout(0.05),\n",
    "            keras.layers.Dense(8, activation='relu'),\n",
    "            keras.layers.Dense(16, activation='relu'),\n",
    "            keras.layers.Dense(D)  # linear head\n",
    "        ])\n",
    "        ae.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse')\n",
    "        cb = [keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)]\n",
    "        ae.fit(X, X, epochs=200, batch_size=256, validation_split=0.15, verbose=0, callbacks=cb)\n",
    "        recon = ae.predict(X, verbose=0)\n",
    "        raw_ae = ((X - recon)**2).mean(axis=1)\n",
    "        ae_source = \"autoencoder\"\n",
    "    else:\n",
    "        pca = PCA(n_components=min(3, X.shape[1]-1 if X.shape[1]>1 else 1), random_state=7)\n",
    "        Z = pca.fit_transform(X)\n",
    "        recon = pca.inverse_transform(Z)\n",
    "        raw_ae = ((X - recon)**2).mean(axis=1)\n",
    "        ae_source = \"pca\"\n",
    "\n",
    "    # ---- Ensemble anomaly percentiles ----\n",
    "    df['if_pct']   = pct_rank(pd.Series(raw_if))\n",
    "    df['ae_pct']   = pct_rank(pd.Series(raw_ae))\n",
    "    df['anom_pct'] = 0.5*df['if_pct'] + 0.5*df['ae_pct']\n",
    "\n",
    "    # ---- NO impact weighting (per request) ----\n",
    "    # Priority = anomaly only\n",
    "    df['priority'] = df['anom_pct']\n",
    "\n",
    "    # ---- Final Rank = average rank of (priority) and (baseline) ----\n",
    "    df['rank_priority'] = df['priority'].rank(ascending=False, method='average')\n",
    "    df['rank_baseline'] = df['baseline_score'].rank(ascending=False, method='average')\n",
    "    df['final_key']     = - (df['rank_priority'] + df['rank_baseline'])/2.0\n",
    "\n",
    "    # ---- Order outputs ----\n",
    "    cols = [\n",
    "        'zip','n_pharmacies','median_income','health_burden',\n",
    "    ]\n",
    "    if 'population' in df.columns: cols += ['population']\n",
    "    if 'land_km2'   in df.columns: cols += ['land_km2']\n",
    "    if 'pop_density'in df.columns: cols += ['pop_density']\n",
    "\n",
    "    cols += [\n",
    "        'pop_per_pharmacy','pharm_per_10k','scarcity',\n",
    "        'scarcity_pct','health_pct','fin_stress_pct','dens_pct',\n",
    "        'baseline_score','if_pct','ae_pct','anom_pct','priority','final_key','lat','lon'\n",
    "    ]\n",
    "    cols = [c for c in cols if c in df.columns]  # keep only present\n",
    "\n",
    "    out = df[cols].sort_values('final_key', ascending=True).reset_index(drop=True)\n",
    "\n",
    "    meta = {\n",
    "        \"ae_source\": ae_source,\n",
    "        \"used_state_relative\": False,\n",
    "        \"used_impact_weighting\": False\n",
    "    }\n",
    "    return out, meta\n",
    "\n",
    "# ----------------------------- Run training & save -----------------------------\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "ranked, meta = build_master(FINANCIAL_CSV, HEALTH_CSV, PHARMACY_CSV, POPULATION_CSV)\n",
    "\n",
    "full_path   = os.path.join(OUT_DIR, \"national_ifae_rank.csv\")\n",
    "top_path    = os.path.join(OUT_DIR, \"top5_ifae.csv\")\n",
    "bottom_path = os.path.join(OUT_DIR, \"bottom5_ifae.csv\")\n",
    "\n",
    "ranked.to_csv(full_path, index=False)\n",
    "ranked.head(TOP_K).to_csv(top_path, index=False)\n",
    "ranked.tail(TOP_K).to_csv(bottom_path, index=False)\n",
    "\n",
    "print(f\"Second detector : {meta['ae_source']} (IF contamination={CONTAMINATION})\")\n",
    "print(f\"State-relative percentiles used for modeling: {meta['used_state_relative']}\")\n",
    "print(f\"Impact weighting used: {meta['used_impact_weighting']}\")\n",
    "print(f\"Saved full rankings to  : {full_path}\")\n",
    "print(f\"Saved top {TOP_K} to    : {top_path}\")\n",
    "print(f\"Saved bottom {TOP_K} to : {bottom_path}\")\n",
    "\n",
    "# ------------------------------- Show results ---------------------------------\n",
    "def _fmt(df):\n",
    "    out = df.copy()\n",
    "    for c in out.select_dtypes(include='number').columns:\n",
    "        out[c] = out[c].astype(float).round(3)\n",
    "    return out\n",
    "\n",
    "print(\"\\nTop candidates:\")\n",
    "show_cols = ['zip','priority','baseline_score','anom_pct','scarcity_pct','health_pct','fin_stress_pct','dens_pct','n_pharmacies']\n",
    "if 'population' in ranked.columns: show_cols.append('population')\n",
    "display(_fmt(ranked.head(TOP_K)[[c for c in show_cols if c in ranked.columns]]))\n",
    "\n",
    "print(\"\\nBottom candidates:\")\n",
    "display(_fmt(ranked.tail(TOP_K)[[c for c in show_cols if c in ranked.columns]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "176d21a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:52:11 +  0.00s] â–¶ Load FINANCIAL (income) ...\n",
      "[20:52:11 +  0.33s] FIN rows=33773, null income=3264\n",
      "[20:52:11 +  0.33s] âœ“ Load FINANCIAL (income) done in 0.33s\n",
      "[20:52:11 +  0.33s] â–¶ Load HEALTH (poor general health %) ...\n",
      "[20:52:11 +  0.55s] HEALTH rows=32520, null health%=0\n",
      "[20:52:11 +  0.55s] âœ“ Load HEALTH (poor general health %) done in 0.22s\n",
      "[20:52:11 +  0.55s] â–¶ Load PHARMACY (access proxy) ...\n",
      "[20:52:12 +  1.24s] PHARMACY unique ZCTA5=14940, total pharmacies=61970\n",
      "[20:52:12 +  1.24s] âœ“ Load PHARMACY (access proxy) done in 0.70s\n",
      "[20:52:12 +  1.24s] â–¶ Load POPULATION (skiprows=10 heuristic + autodetect) ...\n",
      "[20:52:12 +  1.30s] POP rows=40959, null pop=0, land_col=None\n",
      "[20:52:12 +  1.30s] âœ“ Load POPULATION (skiprows=10 heuristic + autodetect) done in 0.05s\n",
      "[20:52:12 +  1.30s] â–¶ Load AQI (annual weighted PM2.5) ...\n",
      "[20:52:14 +  2.84s] AQI rows=125, example:\n",
      "  zip      aqi  obs_total\n",
      "00000 7.016117  7489991.0\n",
      "10065 2.595833       72.0\n",
      "10303 6.532000      150.0\n",
      "[20:52:14 +  2.85s] âœ“ Load AQI (annual weighted PM2.5) done in 1.55s\n",
      "[20:52:14 +  2.85s] â–¶ Load HHI (heat vulnerability) ...\n",
      "[20:52:14 +  2.85s] âœ– Load HHI (heat vulnerability) failed in 0.00s\n",
      "[20:52:14 +  2.85s] â–¶ Merge all features by ZCTA/ZIP ...\n",
      "[20:52:14 +  2.89s] Merged shape: (41094, 7)\n",
      "Null counts (top):\n",
      " aqi                 40969\n",
      "obs_total           40969\n",
      "pharmacies_count    26171\n",
      "S1901_C01_012E      10585\n",
      "GHLTH_CrudePrev      8574\n",
      "population            135\n",
      "ZCTA5                   0\n",
      "[20:52:14 +  2.89s] âœ“ Merge all features by ZCTA/ZIP done in 0.04s\n",
      "[20:52:14 +  2.89s] â–¶ Feature engineering ...\n",
      "[20:52:14 +  2.89s] Range median_income: min=6229.000 max=249688.000 NaN=10585\n",
      "[20:52:14 +  2.89s] Range poor_health_pct: min=3.600 max=56.500 NaN=8574\n",
      "[20:52:14 +  2.89s] Range pharm_per_10k: min=0.000 max=2000.000 NaN=1064\n",
      "[20:52:14 +  2.89s] Range population: min=0.000 max=122814.000 NaN=135\n",
      "[20:52:14 +  2.89s] Range pop_density: min=nan max=nan NaN=41094\n",
      "[20:52:14 +  2.90s] Range aqi: min=2.596 max=15.008 NaN=40969\n",
      "[20:52:14 +  2.90s] âœ“ Feature engineering done in 0.01s\n",
      "[20:52:14 +  2.90s] â–¶ Compute composite & train IsolationForest ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/5gzqwh3d5sx43n9fsy97czyc0000gn/T/ipykernel_54177/1835354442.py:104: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grp_annual = df.groupby('zip', as_index=False).apply(\n",
      "/var/folders/9d/5gzqwh3d5sx43n9fsy97czyc0000gn/T/ipykernel_54177/1835354442.py:226: UserWarning: HHI not loaded: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.\n",
      "  warnings.warn(f\"HHI not loaded: {e}\")\n",
      "/var/folders/9d/5gzqwh3d5sx43n9fsy97czyc0000gn/T/ipykernel_54177/1835354442.py:285: RuntimeWarning: All-NaN axis encountered\n",
      "  stamp(f\"Range {col}: min={np.nanmin(x):.3f} max={np.nanmax(x):.3f} NaN={np.isnan(x).sum()}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:52:14 +  3.36s] âœ“ Compute composite & train IsolationForest done in 0.47s\n",
      "[20:52:14 +  3.37s] â–¶ Finalize outputs ...\n",
      "[20:52:14 +  3.56s] Wrote results/national_ifae_rank.csv\n",
      "[20:52:14 +  3.56s] Wrote results/top5_ifae.csv\n",
      "[20:52:14 +  3.56s] Wrote results/bottom5_ifae.csv\n",
      "\n",
      "Top 5 preview:\n",
      " ZCTA5  IFAE_score  composite  iforest_anomaly  median_income  poor_health_pct  population  pharmacies_count  pharm_per_10k  income_norm_inv  health_norm  access_norm_inv  density_norm  pop_density  pop_norm   aqi  aqi_norm  obs_total\n",
      "06702    0.791762   0.769051         0.814474        16198.0             47.2      3025.0               3.0       9.917355         0.959053     0.824197         0.995041           0.0          NaN  0.024631   NaN       NaN        NaN\n",
      "44702    0.783916   0.712806         0.855025        13159.0             36.6       948.0               3.0      31.645570         0.971535     0.623819         0.984177           0.0          NaN  0.007719   NaN       NaN        NaN\n",
      "41643    0.782309   0.691377         0.873241        24310.0             37.7        73.0               1.0     136.986301         0.925733     0.644612         0.931507           0.0          NaN  0.000594   NaN       NaN        NaN\n",
      "39630    0.778268   0.708975         0.847561        25724.0             38.5       785.0               3.0      38.216561         0.919925     0.659735         0.980892           0.0          NaN  0.006392   NaN       NaN        NaN\n",
      "86434    0.772872   0.748667         0.797076        42292.0             41.0      1657.0               1.0       6.035003         0.851872     0.706994         0.996982           0.0          NaN  0.013492 8.592  0.483072       25.0\n",
      "\n",
      "Bottom 5 preview:\n",
      " ZCTA5  IFAE_score  composite  iforest_anomaly  median_income  poor_health_pct  population  pharmacies_count  pharm_per_10k  income_norm_inv  health_norm  access_norm_inv  density_norm  pop_density  pop_norm  aqi  aqi_norm  obs_total\n",
      "38302    0.202056        0.3         0.104111            NaN              NaN     33168.0               0.0            0.0              NaN          NaN              1.0           0.0          NaN  0.270067  NaN       NaN        NaN\n",
      "38303    0.202056        0.3         0.104111            NaN              NaN     33168.0               0.0            0.0              NaN          NaN              1.0           0.0          NaN  0.270067  NaN       NaN        NaN\n",
      "38308    0.202056        0.3         0.104111            NaN              NaN     52662.0               0.0            0.0              NaN          NaN              1.0           0.0          NaN  0.428795  NaN       NaN        NaN\n",
      "38314    0.202056        0.3         0.104111            NaN              NaN      3110.0               0.0            0.0              NaN          NaN              1.0           0.0          NaN  0.025323  NaN       NaN        NaN\n",
      "99950    0.202056        0.3         0.104111            NaN              NaN      2484.0               0.0            0.0              NaN          NaN              1.0           0.0          NaN  0.020226  NaN       NaN        NaN\n",
      "[20:52:14 +  3.57s] âœ“ Finalize outputs done in 0.20s\n",
      "[20:52:14 +  3.57s] All done. ðŸš€\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IFAE (Income-Health-Access Equity) ZIP/ZCTA Ranking â€” with AQI + HHI\n",
    "# - Transparent, tweakable composite (no state-relative, no impact weighting)\n",
    "# - IsolationForest anomaly on the same normalized features\n",
    "# - Integrates:\n",
    "#     * AQI annual weighted average per ZIP (PM2.5): read_aqi_data()\n",
    "#     * HHI Excel (heat vulnerability): read_hhi_excel()\n",
    "# Outputs:\n",
    "#   results/national_ifae_rank.csv\n",
    "#   results/top5_ifae.csv\n",
    "#   results/bottom5_ifae.csv\n",
    "# =============================================================================\n",
    "\n",
    "import os, time, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# === CONFIG: set your file paths here ===\n",
    "FINANCIAL_CSV  = \"data/financial_data.csv\"      # needs: NAME, S1901_C01_012E (median HH income)\n",
    "HEALTH_CSV     = \"data/health_data.csv\"         # needs: ZCTA5, GHLTH_CrudePrev\n",
    "PHARMACY_CSV   = \"data/pharmacy_data.csv\"       # needs: ZIP, NAME, X, Y\n",
    "POPULATION_CSV = \"data/population_data.csv\"     # teammate used skiprows=10; autodetect columns\n",
    "\n",
    "# NEW:\n",
    "AQI_CSV        = \"data/AQI_data.csv\"            # PM2.5; arbitrary columns but should include ZIP, Observation Count, Arithmetic Mean, Month/Date Local\n",
    "HHI_XLSX       = \"data/HHI_data.xlsx\"           # Excel; must include ZCTA and HHB_SCORE (optional: NBE_SCORE, OVERALL_SCORE)\n",
    "\n",
    "OUT_DIR        = \"results\"\n",
    "CONTAMINATION  = 0.03\n",
    "TOP_K          = 10\n",
    "\n",
    "# ---------- Monitoring helpers ----------\n",
    "_T0 = time.time()\n",
    "def stamp(msg):\n",
    "    now = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(f\"[{now} +{time.time()-_T0:6.2f}s] {msg}\", flush=True)\n",
    "\n",
    "class Step:\n",
    "    def __init__(self, name): self.name=name; self.t0=None\n",
    "    def __enter__(self): self.t0=time.time(); stamp(f\"â–¶ {self.name} ...\"); return self\n",
    "    def __exit__(self, et, ev, tb):\n",
    "        dt = time.time()-self.t0\n",
    "        stamp((\"âœ“ \" if et is None else \"âœ– \") + f\"{self.name} {'done' if et is None else 'failed'} in {dt:.2f}s\")\n",
    "\n",
    "def read_csv_smart(path, **kw):\n",
    "    p = Path(path)\n",
    "    if not p.exists(): raise FileNotFoundError(f\"Missing file: {path}\")\n",
    "    try:\n",
    "        return pd.read_csv(path, low_memory=False, **kw)\n",
    "    except Exception as e:\n",
    "        stamp(f\"CSV read warning: {e}. Retrying with simpler defaults.\")\n",
    "        return pd.read_csv(path)\n",
    "\n",
    "def minmax(s):\n",
    "    x = pd.to_numeric(s, errors='coerce')\n",
    "    mn, mx = x.min(skipna=True), x.max(skipna=True)\n",
    "    if np.isnan(mn) or np.isnan(mx) or mx==mn:\n",
    "        return pd.Series(0.0, index=x.index)\n",
    "    return (x - mn) / (mx - mn)\n",
    "\n",
    "def coerce_zcta(series):\n",
    "    \"\"\"Return 5-digit, zero-padded strings; strips non-digit chars if present.\"\"\"\n",
    "    s = series.astype(str).str.extract(r\"(\\d{3,5})\", expand=False)\n",
    "    return s.fillna(\"\").str.zfill(5)\n",
    "\n",
    "def nonint_fraction(x: pd.Series) -> float:\n",
    "    x = pd.to_numeric(x, errors='coerce')\n",
    "    return float((np.abs(x - np.round(x)) > 1e-9).mean())\n",
    "\n",
    "# ---------- New loaders: AQI + HHI ----------\n",
    "def read_aqi_data(file_path):\n",
    "    \"\"\"\n",
    "    Reads AQI/PM2.5-like CSV and aggregates to:\n",
    "      - annual weighted average per ZIP (by Observation Count)\n",
    "    Returns: aqi_annual: [zip, aqi, obs_total]\n",
    "    \"\"\"\n",
    "    df = read_csv_smart(file_path)\n",
    "    # choose ZIP column (some files have ZIP and ZIP.1)\n",
    "    zip_cols = [c for c in df.columns if str(c).upper().startswith('ZIP')]\n",
    "    if not zip_cols:\n",
    "        raise KeyError(\"AQI CSV needs a ZIP column.\")\n",
    "    zip_col = zip_cols[-1]\n",
    "    df['zip'] = df[zip_col].astype(str).str.extract(r'(\\d{5})')[0].fillna('').str.zfill(5)\n",
    "\n",
    "    if 'Arithmetic Mean' not in df.columns or 'Observation Count' not in df.columns:\n",
    "        raise KeyError(\"AQI CSV must include 'Arithmetic Mean' and 'Observation Count' columns.\")\n",
    "    val_col = 'Arithmetic Mean'\n",
    "    w_col   = 'Observation Count'\n",
    "    df[val_col] = pd.to_numeric(df[val_col], errors='coerce')\n",
    "    df[w_col]   = pd.to_numeric(df[w_col], errors='coerce').fillna(0)\n",
    "\n",
    "    # Restrict to PM2.5 if present\n",
    "    if 'Parameter Name' in df.columns:\n",
    "        df = df[df['Parameter Name'].astype(str).str.contains('PM2.5', na=False)]\n",
    "\n",
    "    # Drop junk\n",
    "    df = df.dropna(subset=['zip', val_col])\n",
    "    df = df[df[w_col] > 0]\n",
    "\n",
    "    # Annual weighted average per ZIP\n",
    "    grp_annual = df.groupby('zip', as_index=False).apply(\n",
    "        lambda g: pd.Series({\n",
    "            'aqi': np.average(g[val_col], weights=g[w_col]),\n",
    "            'obs_total': g[w_col].sum()\n",
    "        })\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return grp_annual[['zip','aqi','obs_total']]\n",
    "\n",
    "def read_hhi_excel(file_path):\n",
    "    \"\"\"\n",
    "    Reads Heat-Health Index (HHI) Excel and returns:\n",
    "      [zip, heat_hhb, nbe_score?, hhi_overall?]\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file_path, dtype={'ZCTA': str})\n",
    "    if 'ZCTA' not in df.columns:\n",
    "        raise ValueError(\"HHI Excel must contain 'ZCTA' column.\")\n",
    "    df['zip'] = df['ZCTA'].astype(str).str.extract(r'(\\d{5})')[0].fillna('').str.zfill(5)\n",
    "\n",
    "    out = pd.DataFrame({'zip': df['zip']})\n",
    "    if 'HHB_SCORE' in df.columns:\n",
    "        out['heat_hhb'] = pd.to_numeric(df['HHB_SCORE'], errors='coerce')\n",
    "    if 'NBE_SCORE' in df.columns:\n",
    "        out['nbe_score'] = pd.to_numeric(df['NBE_SCORE'], errors='coerce')\n",
    "    if 'OVERALL_SCORE' in df.columns:\n",
    "        out['hhi_overall'] = pd.to_numeric(df['OVERALL_SCORE'], errors='coerce')\n",
    "\n",
    "    return out.dropna(subset=['zip']).drop_duplicates(subset=['zip'])\n",
    "\n",
    "# ---------- Load & prepare each source ----------\n",
    "with Step(\"Load FINANCIAL (income)\"):\n",
    "    fin = read_csv_smart(FINANCIAL_CSV)\n",
    "    zcta_col = None\n",
    "    for cand in [\"ZCTA5\",\"zcta5\",\"ZCTA\",\"zcta\",\"ZIP\",\"Zip\",\"NAME\",\"Name\",\"name\"]:\n",
    "        if cand in fin.columns:\n",
    "            zcta_col = cand; break\n",
    "    if zcta_col is None:\n",
    "        raise KeyError(f\"Could not find a ZCTA/ZIP column in {FINANCIAL_CSV}. Columns: {list(fin.columns)[:10]} ...\")\n",
    "    if \"S1901_C01_012E\" not in fin.columns:\n",
    "        raise KeyError(\"Missing S1901_C01_012E (median HH income) in FINANCIAL_CSV.\")\n",
    "    fin = fin.rename(columns={zcta_col:\"ZCTA5\"})\n",
    "    fin[\"ZCTA5\"] = coerce_zcta(fin[\"ZCTA5\"])\n",
    "    fin = fin[[\"ZCTA5\",\"S1901_C01_012E\"]].copy()\n",
    "    fin[\"S1901_C01_012E\"] = pd.to_numeric(fin[\"S1901_C01_012E\"], errors=\"coerce\")\n",
    "    stamp(f\"FIN rows={len(fin)}, null income={fin['S1901_C01_012E'].isna().sum()}\")\n",
    "\n",
    "with Step(\"Load HEALTH (poor general health %)\"):\n",
    "    hlth = read_csv_smart(HEALTH_CSV)\n",
    "    if \"ZCTA5\" not in hlth.columns:\n",
    "        for cand in [\"ZCTA\",\"zcta\",\"ZIP\",\"Zip\",\"name\",\"NAME\"]:\n",
    "            if cand in hlth.columns:\n",
    "                hlth = hlth.rename(columns={cand:\"ZCTA5\"})\n",
    "                break\n",
    "    if \"ZCTA5\" not in hlth.columns or \"GHLTH_CrudePrev\" not in hlth.columns:\n",
    "        raise KeyError(\"HEALTH_CSV must contain ZCTA5 and GHLTH_CrudePrev.\")\n",
    "    hlth[\"ZCTA5\"] = coerce_zcta(hlth[\"ZCTA5\"])\n",
    "    hlth[\"GHLTH_CrudePrev\"] = pd.to_numeric(hlth[\"GHLTH_CrudePrev\"], errors=\"coerce\")\n",
    "    hlth = hlth[[\"ZCTA5\",\"GHLTH_CrudePrev\"]]\n",
    "    stamp(f\"HEALTH rows={len(hlth)}, null health%={hlth['GHLTH_CrudePrev'].isna().sum()}\")\n",
    "\n",
    "with Step(\"Load PHARMACY (access proxy)\"):\n",
    "    ph = read_csv_smart(PHARMACY_CSV)\n",
    "    for needed in [\"ZIP\",\"NAME\"]:\n",
    "        if needed not in ph.columns:\n",
    "            raise KeyError(f\"PHARMACY_CSV must contain {needed}.\")\n",
    "    ph[\"ZCTA5\"] = coerce_zcta(ph[\"ZIP\"])\n",
    "    ph_cnt = ph.groupby(\"ZCTA5\", dropna=False)[\"NAME\"].nunique(dropna=True).reset_index()\n",
    "    ph_cnt = ph_cnt.rename(columns={\"NAME\":\"pharmacies_count\"})\n",
    "    stamp(f\"PHARMACY unique ZCTA5={ph_cnt['ZCTA5'].nunique()}, total pharmacies={ph_cnt['pharmacies_count'].sum()}\")\n",
    "\n",
    "with Step(\"Load POPULATION (skiprows=10 heuristic + autodetect)\"):\n",
    "    pop = read_csv_smart(POPULATION_CSV, skiprows=10)\n",
    "    code_col = None\n",
    "    for cand in [\"ZCTA5\",\"ZCTA\",\"ZIP\",\"Zip\",\"GEOID\",\"geoid\",\"NAME\",\"name\"]:\n",
    "        if cand in pop.columns:\n",
    "            code_col=cand; break\n",
    "    if code_col is None:\n",
    "        obj_cols = [c for c in pop.columns if pop[c].dtype == object]\n",
    "        code_col = obj_cols[0] if obj_cols else pop.columns[0]\n",
    "    pop = pop.rename(columns={code_col:\"ZCTA5\"})\n",
    "    pop[\"ZCTA5\"] = coerce_zcta(pop[\"ZCTA5\"])\n",
    "\n",
    "    pop_col = None\n",
    "    for cand in [\"POP\",\"Population\",\"population\",\"TOTAL_POP\",\"TotPop\",\"DP05_0001E\",\"pop\"]:\n",
    "        if cand in pop.columns:\n",
    "            pop_col=cand; break\n",
    "    if pop_col is None:\n",
    "        num_cols = [c for c in pop.columns if pd.api.types.is_numeric_dtype(pop[c])]\n",
    "        sums = {c: pd.to_numeric(pop[c], errors=\"coerce\").sum(skipna=True) for c in num_cols}\n",
    "        pop_col = max(sums, key=sums.get) if sums else None\n",
    "    if pop_col is None:\n",
    "        raise KeyError(\"Could not infer population column in POPULATION_CSV.\")\n",
    "\n",
    "    land_col = None\n",
    "    for cand in [\"land_area_km2\",\"Land_Area_km2\",\"ALAND_KM2\",\"aland_km2\",\"ALAND\",\"area\",\"AREA_KM2\",\"ALAND_SQMI\",\"AREALAND\"]:\n",
    "        if cand in pop.columns:\n",
    "            land_col = cand; break\n",
    "\n",
    "    keep_cols = [\"ZCTA5\", pop_col] + ([land_col] if land_col else [])\n",
    "    pop = pop[keep_cols].copy()\n",
    "    pop = pop.rename(columns={pop_col:\"population\"})\n",
    "    pop[\"population\"] = pd.to_numeric(pop[\"population\"], errors=\"coerce\")\n",
    "    if land_col:\n",
    "        pop = pop.rename(columns={land_col:\"land_area_raw\"})\n",
    "        pop[\"land_area_raw\"] = pd.to_numeric(pop[\"land_area_raw\"], errors=\"coerce\")\n",
    "    stamp(f\"POP rows={len(pop)}, null pop={pop['population'].isna().sum()}, land_col={land_col}\")\n",
    "\n",
    "# NEW: load AQI + HHI (optional; skip if files missing)\n",
    "try:\n",
    "    with Step(\"Load AQI (annual weighted PM2.5)\"):\n",
    "        aqi_annual = read_aqi_data(AQI_CSV)\n",
    "        stamp(f\"AQI rows={len(aqi_annual)}, example:\\n{aqi_annual.head(3).to_string(index=False)}\")\n",
    "except Exception as e:\n",
    "    aqi_annual = None\n",
    "    warnings.warn(f\"AQI not loaded: {e}\")\n",
    "\n",
    "try:\n",
    "    with Step(\"Load HHI (heat vulnerability)\"):\n",
    "        hhi = read_hhi_excel(HHI_XLSX)\n",
    "        stamp(f\"HHI rows={len(hhi)}, example:\\n{hhi.head(3).to_string(index=False)}\")\n",
    "except Exception as e:\n",
    "    hhi = None\n",
    "    warnings.warn(f\"HHI not loaded: {e}\")\n",
    "\n",
    "# ---------- Merge all to ZCTA frame ----------\n",
    "with Step(\"Merge all features by ZCTA/ZIP\"):\n",
    "    df = fin.merge(hlth, on=\"ZCTA5\", how=\"outer\") \\\n",
    "            .merge(pop, on=\"ZCTA5\", how=\"outer\") \\\n",
    "            .merge(ph_cnt, on=\"ZCTA5\", how=\"left\")\n",
    "    if aqi_annual is not None and not aqi_annual.empty:\n",
    "        df = df.merge(aqi_annual.rename(columns={'zip':'ZCTA5'}), on=\"ZCTA5\", how=\"left\")\n",
    "    if hhi is not None and not hhi.empty:\n",
    "        df = df.merge(hhi.rename(columns={'zip':'ZCTA5'}), on=\"ZCTA5\", how=\"left\")\n",
    "    stamp(f\"Merged shape: {df.shape}\")\n",
    "    print(\"Null counts (top):\\n\", df.isna().sum().sort_values(ascending=False).head(10).to_string(), flush=True)\n",
    "\n",
    "# ---------- Feature engineering ----------\n",
    "with Step(\"Feature engineering\"):\n",
    "    # income\n",
    "    df[\"median_income\"] = pd.to_numeric(df[\"S1901_C01_012E\"], errors=\"coerce\")\n",
    "    # health burden\n",
    "    df[\"poor_health_pct\"] = pd.to_numeric(df[\"GHLTH_CrudePrev\"], errors=\"coerce\")\n",
    "    # pharmacies\n",
    "    df[\"pharmacies_count\"] = pd.to_numeric(df[\"pharmacies_count\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "    # pharmacies per 10k (guard against div by zero)\n",
    "    df[\"pharm_per_10k\"] = np.where(df[\"population\"].gt(0),\n",
    "                                   1e4 * df[\"pharmacies_count\"] / df[\"population\"],\n",
    "                                   np.nan)\n",
    "\n",
    "    # population density if land provided; convert sq meters to km2 if needed\n",
    "    if \"land_area_raw\" in df.columns:\n",
    "        med_area = np.nanmedian(df[\"land_area_raw\"])\n",
    "        if np.isfinite(med_area) and med_area > 1e5:\n",
    "            df[\"land_area_km2\"] = df[\"land_area_raw\"] / 1e6\n",
    "        else:\n",
    "            df[\"land_area_km2\"] = df[\"land_area_raw\"]\n",
    "        df[\"pop_density\"] = np.where(df[\"land_area_km2\"].gt(0),\n",
    "                                     df[\"population\"] / df[\"land_area_km2\"],\n",
    "                                     np.nan)\n",
    "    else:\n",
    "        df[\"pop_density\"] = np.nan\n",
    "\n",
    "    # NEW: AQI (higher = worse); HHI heat_hhb (higher = worse)\n",
    "    if 'aqi' in df.columns:\n",
    "        df['aqi'] = pd.to_numeric(df['aqi'], errors='coerce')\n",
    "    if 'heat_hhb' in df.columns:\n",
    "        df['heat_hhb'] = pd.to_numeric(df['heat_hhb'], errors='coerce')\n",
    "\n",
    "    # Normalizations (0..1, higher = worse)\n",
    "    df[\"income_norm_inv\"]   = 1.0 - minmax(df[\"median_income\"])\n",
    "    df[\"health_norm\"]       = minmax(df[\"poor_health_pct\"])\n",
    "    df[\"access_norm_inv\"]   = 1.0 - minmax(df[\"pharm_per_10k\"])\n",
    "    df[\"pop_norm\"]          = minmax(df[\"population\"])     # used only in reporting; NOT a rank weight\n",
    "    df[\"density_norm\"]      = minmax(df[\"pop_density\"])\n",
    "    df[\"aqi_norm\"]          = minmax(df[\"aqi\"]) if 'aqi' in df.columns else 0.0\n",
    "    df[\"heat_norm\"]         = minmax(df[\"heat_hhb\"]) if 'heat_hhb' in df.columns else 0.0\n",
    "\n",
    "    for col in [\"median_income\",\"poor_health_pct\",\"pharm_per_10k\",\"population\",\"pop_density\",\"aqi\",\"heat_hhb\"]:\n",
    "        if col in df.columns:\n",
    "            x = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "            stamp(f\"Range {col}: min={np.nanmin(x):.3f} max={np.nanmax(x):.3f} NaN={np.isnan(x).sum()}\")\n",
    "\n",
    "# ---------- Composite + IsolationForest ----------\n",
    "with Step(\"Compute composite & train IsolationForest\"):\n",
    "    # Transparent composite (tweakable weights; sum to 1)\n",
    "    # Emphasize: access, health, income; include AQI & heat if present; tiny weight for density.\n",
    "    has_aqi  = ('aqi_norm'  in df.columns) and (df['aqi_norm'].dtype != object)\n",
    "    has_heat = ('heat_norm' in df.columns) and (df['heat_norm'].dtype != object)\n",
    "\n",
    "    if has_aqi and has_heat:\n",
    "        w_income, w_health, w_access, w_aqi, w_heat, w_density = 0.25, 0.28, 0.30, 0.08, 0.07, 0.02\n",
    "    elif has_aqi and not has_heat:\n",
    "        w_income, w_health, w_access, w_aqi, w_heat, w_density = 0.27, 0.30, 0.33, 0.08, 0.00, 0.02\n",
    "    elif has_heat and not has_aqi:\n",
    "        w_income, w_health, w_access, w_aqi, w_heat, w_density = 0.27, 0.30, 0.33, 0.00, 0.08, 0.02\n",
    "    else:\n",
    "        w_income, w_health, w_access, w_aqi, w_heat, w_density = 0.30, 0.35, 0.33, 0.00, 0.00, 0.02\n",
    "\n",
    "    df[\"composite\"] = (\n",
    "        w_income  * df[\"income_norm_inv\"].fillna(0) +\n",
    "        w_health  * df[\"health_norm\"].fillna(0) +\n",
    "        w_access  * df[\"access_norm_inv\"].fillna(0) +\n",
    "        w_aqi     * (df[\"aqi_norm\"].fillna(0)   if has_aqi  else 0) +\n",
    "        w_heat    * (df[\"heat_norm\"].fillna(0)  if has_heat else 0) +\n",
    "        w_density * df[\"density_norm\"].fillna(0)\n",
    "    )\n",
    "\n",
    "    # IF features = the same normalized vector as composite (no state-relative, no impact weighting)\n",
    "    feat_cols = [\"income_norm_inv\",\"health_norm\",\"access_norm_inv\",\"density_norm\"]\n",
    "    if has_aqi:  feat_cols.append(\"aqi_norm\")\n",
    "    if has_heat: feat_cols.append(\"heat_norm\")\n",
    "    feats = df[feat_cols].fillna(0.0).values\n",
    "\n",
    "    iforest = IsolationForest(random_state=42, contamination=CONTAMINATION, n_estimators=200, n_jobs=-1)\n",
    "    iforest.fit(feats)\n",
    "    decision = iforest.decision_function(feats)  # higher -> more \"normal\"\n",
    "    inv = -decision\n",
    "    inv = (inv - inv.min()) / (inv.max() - inv.min() + 1e-12)  # 0..1\n",
    "    df[\"iforest_anomaly\"] = inv\n",
    "\n",
    "    # Final IFAE score = 0.5*composite + 0.5*iforest_anomaly (no population/density impact multiplier)\n",
    "    df[\"IFAE_score\"] = 0.5 * df[\"composite\"] + 0.5 * df[\"iforest_anomaly\"]\n",
    "\n",
    "with Step(\"Finalize outputs\"):\n",
    "    out = Path(OUT_DIR); out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    keep = [\n",
    "        \"ZCTA5\",\"IFAE_score\",\"composite\",\"iforest_anomaly\",\n",
    "        \"median_income\",\"poor_health_pct\",\"population\",\"pharmacies_count\",\"pharm_per_10k\",\n",
    "        \"income_norm_inv\",\"health_norm\",\"access_norm_inv\",\"density_norm\",\"pop_density\",\"pop_norm\"\n",
    "    ]\n",
    "    if 'aqi' in df.columns:\n",
    "        keep += ['aqi','aqi_norm','obs_total']\n",
    "    if 'heat_hhb' in df.columns:\n",
    "        keep += ['heat_hhb','heat_norm']\n",
    "    if 'nbe_score' in df.columns:     keep += ['nbe_score']\n",
    "    if 'hhi_overall' in df.columns:   keep += ['hhi_overall']\n",
    "\n",
    "    keep = [c for c in keep if c in df.columns]\n",
    "    ranked = df[keep].copy().sort_values(\"IFAE_score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    national_path = out / \"national_ifae_rank.csv\"\n",
    "    topk_path     = out / \"top5_ifae.csv\"\n",
    "    bottomk_path  = out / \"bottom5_ifae.csv\"\n",
    "\n",
    "    ranked.to_csv(national_path, index=False)\n",
    "    ranked.head(TOP_K).to_csv(topk_path, index=False)      # <-- Top K (best)\n",
    "    ranked.tail(TOP_K).to_csv(bottomk_path, index=False)   # <-- Bottom K\n",
    "\n",
    "    stamp(f\"Wrote {national_path}\")\n",
    "    stamp(f\"Wrote {topk_path}\")\n",
    "    stamp(f\"Wrote {bottomk_path}\")\n",
    "    print(\"\\nTop 5 preview:\\n\", ranked.head(5).to_string(index=False))\n",
    "    print(\"\\nBottom 5 preview:\\n\", ranked.tail(5).to_string(index=False))\n",
    "\n",
    "stamp(\"All done. ðŸš€\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b67bf52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:49:24 +  0.00s] â–¶ Load FINANCIAL (income) ...\n",
      "[08:49:24 +  0.32s] FIN rows=33773, null income=3264\n",
      "[08:49:24 +  0.32s] âœ“ Load FINANCIAL (income) done in 0.32s\n",
      "[08:49:24 +  0.32s] â–¶ Load HEALTH (poor general health %) ...\n",
      "[08:49:24 +  0.53s] HEALTH rows=32520, null health%=0\n",
      "[08:49:24 +  0.53s] âœ“ Load HEALTH (poor general health %) done in 0.21s\n",
      "[08:49:24 +  0.53s] â–¶ Load PHARMACY (access) ...\n",
      "[08:49:25 +  1.20s] PHARMACY unique ZCTA5=14940, pharmacies=61970\n",
      "[08:49:25 +  1.20s] âœ“ Load PHARMACY (access) done in 0.67s\n",
      "[08:49:25 +  1.20s] â–¶ Load POPULATION (skiprows=10 + autodetect) ...\n",
      "[08:49:25 +  1.26s] POP rows=40959, null pop=0, land_col=None\n",
      "[08:49:25 +  1.26s] âœ“ Load POPULATION (skiprows=10 + autodetect) done in 0.06s\n",
      "[08:49:25 +  1.26s] â–¶ Load AQI (annual weighted PM2.5) ...\n",
      "[08:49:26 +  2.85s] AQI rows=125 (coverage ~0.3%)\n",
      "[08:49:26 +  2.85s] âœ“ Load AQI (annual weighted PM2.5) done in 1.59s\n",
      "[08:49:26 +  2.85s] â–¶ Load HHI (heat vulnerability) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/5gzqwh3d5sx43n9fsy97czyc0000gn/T/ipykernel_54177/2731130997.py:98: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  grp_annual = df.groupby('zip', as_index=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:49:33 +  9.77s] HHI rows=32092\n",
      "[08:49:33 +  9.77s] âœ“ Load HHI (heat vulnerability) done in 6.93s\n",
      "[08:49:33 +  9.77s] â–¶ Merge all features by ZCTA/ZIP ...\n",
      "[08:49:33 +  9.81s] Merged shape: (41094, 10)\n",
      "[08:49:33 +  9.82s] âœ“ Merge all features by ZCTA/ZIP done in 0.04s\n",
      "[08:49:33 +  9.82s] â–¶ Feature engineering ...\n",
      "[08:49:33 +  9.83s] âœ“ Feature engineering done in 0.02s\n",
      "[08:49:33 +  9.83s] â–¶ Compute composite & train IsolationForest ...\n",
      "Coverage: {'aqi': np.float64(0.003041806589769796), 'heat': np.float64(0.7806979121039568), 'density': np.float64(0.0)}\n",
      "[08:49:34 + 10.25s] âœ“ Compute composite & train IsolationForest done in 0.42s\n",
      "[08:49:34 + 10.25s] â–¶ Finalize outputs ...\n",
      "[08:49:34 + 10.46s] Wrote results/national_ifae_rank.csv\n",
      "[08:49:34 + 10.46s] Wrote results/top5_ifae.csv (pop â‰¥ 1000)\n",
      "[08:49:34 + 10.46s] Wrote results/bottom5_ifae.csv\n",
      "\n",
      "Top 5 (pop â‰¥ 1,000) preview:\n",
      " ZCTA5  IFAE_score  composite  iforest_anomaly  median_income  poor_health_pct  population  pharmacies_count  pop_per_pharmacy  income_pct_inv  health_pct  access_pct_inv  density_pct  pop_density  aqi  aqi_pct  obs_total  heat_hhb  heat_pct\n",
      "77026    0.898475   0.964502         0.832449        34835.0             38.5     22380.0               0.0           22380.0        0.972867    0.994513        0.928279          0.5          NaN  NaN      0.5        NaN    0.8653  0.921576\n",
      "92274    0.893781   0.955742         0.831820        36087.0             38.5     15118.0               0.0           15118.0        0.969229    0.994513        0.894229          0.5          NaN  NaN      0.5        NaN    0.9620  0.972508\n",
      "01105    0.886949   0.953970         0.819928        22994.0             37.1     11957.0               1.0           11957.0        0.994464    0.991094        0.870147          0.5          NaN  NaN      0.5        NaN    0.9240  0.954086\n",
      "06120    0.879593   0.946891         0.812294        33521.0             32.1     14534.0               1.0           14534.0        0.977053    0.967501        0.890257          0.5          NaN  NaN      0.5        NaN    0.9374  0.961443\n",
      "89115    0.875552   0.942701         0.808403        49648.0             33.9     61811.0               2.0           30905.5        0.881954    0.978780        0.955733          0.5          NaN  NaN      0.5        NaN    0.9686  0.976435\n",
      "\n",
      "Bottom 5 preview:\n",
      " ZCTA5  IFAE_score  composite  iforest_anomaly  median_income  poor_health_pct  population  pharmacies_count  pop_per_pharmacy  income_pct_inv  health_pct  access_pct_inv  density_pct  pop_density  aqi  aqi_pct  obs_total  heat_hhb  heat_pct\n",
      "78716    0.247185   0.426131         0.068239        69953.0             19.2       860.0               0.0             860.0        0.499988     0.49972        0.254109          0.5          NaN  NaN      0.5        NaN       NaN       0.5\n",
      "78714    0.247185   0.426131         0.068239        69953.0             19.2       860.0               0.0             860.0        0.499988     0.49972        0.254109          0.5          NaN  NaN      0.5        NaN       NaN       0.5\n",
      "19360    0.247084   0.425929         0.068239        69953.0             19.2       855.0               0.0             855.0        0.499988     0.49972        0.253435          0.5          NaN  NaN      0.5        NaN       NaN       0.5\n",
      "40405    0.247028   0.425816         0.068239        69953.0             19.2       853.0               0.0             853.0        0.499988     0.49972        0.253060          0.5          NaN  NaN      0.5        NaN       NaN       0.5\n",
      "71359    0.246994   0.425749         0.068239        69953.0             19.2       852.0               0.0             852.0        0.499988     0.49972        0.252835          0.5          NaN  NaN      0.5        NaN       NaN       0.5\n",
      "[08:49:34 + 10.46s] âœ“ Finalize outputs done in 0.21s\n",
      "[08:49:34 + 10.46s] All done. ðŸš€\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IFAE (Income-Health-Access Equity) ZIP/ZCTA Ranking â€” with AQI + HHI\n",
    "# - Composite (percentiles) + IsolationForest anomaly\n",
    "# - Population-based access (people per pharmacy)\n",
    "# - Auto-disable low-coverage features; impute income/health by national medians\n",
    "# - No state-relative, no population/density impact weighting\n",
    "#\n",
    "# Outputs:\n",
    "#   results/national_ifae_rank.csv   (full ranking)\n",
    "#   results/top5_ifae.csv            (top K with population >= 1,000)\n",
    "#   results/bottom5_ifae.csv         (bottom K)\n",
    "# =============================================================================\n",
    "\n",
    "import os, time, warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# === CONFIG: set your file paths here ===\n",
    "FINANCIAL_CSV  = \"data/financial_data.csv\"      # needs: NAME, S1901_C01_012E (median HH income)\n",
    "HEALTH_CSV     = \"data/health_data.csv\"         # needs: ZCTA5, GHLTH_CrudePrev\n",
    "PHARMACY_CSV   = \"data/pharmacy_data.csv\"       # needs: ZIP, NAME, X, Y (X/Y optional)\n",
    "POPULATION_CSV = \"data/population_data.csv\"     # teammate used skiprows=10; autodetect columns\n",
    "\n",
    "# Optional extras (will be auto-disabled if missing/low coverage)\n",
    "AQI_CSV        = \"data/AQI_data.csv\"            # PM2.5; must include ZIP, Arithmetic Mean, Observation Count\n",
    "HHI_XLSX       = \"data/HHI_data.xlsx\"           # Excel; must include ZCTA, HHB_SCORE (heat)\n",
    "\n",
    "OUT_DIR        = \"results\"\n",
    "CONTAMINATION  = 0.03\n",
    "TOP_K          = 10\n",
    "MIN_POP_TOPK   = 1000   # population gate for top-k presentation\n",
    "\n",
    "# ---------- Monitoring helpers ----------\n",
    "_T0 = time.time()\n",
    "def stamp(msg):\n",
    "    now = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    print(f\"[{now} +{time.time()-_T0:6.2f}s] {msg}\", flush=True)\n",
    "\n",
    "class Step:\n",
    "    def __init__(self, name): self.name=name; self.t0=None\n",
    "    def __enter__(self): self.t0=time.time(); stamp(f\"â–¶ {self.name} ...\"); return self\n",
    "    def __exit__(self, et, ev, tb):\n",
    "        dt = time.time()-self.t0\n",
    "        stamp((\"âœ“ \" if et is None else \"âœ– \") + f\"{self.name} {'done' if et is None else 'failed'} in {dt:.2f}s\")\n",
    "\n",
    "def read_csv_smart(path, **kw):\n",
    "    p = Path(path)\n",
    "    if not p.exists(): raise FileNotFoundError(f\"Missing file: {path}\")\n",
    "    try:\n",
    "        return pd.read_csv(path, low_memory=False, **kw)\n",
    "    except Exception as e:\n",
    "        stamp(f\"CSV read warning: {e}. Retrying with simpler defaults.\")\n",
    "        return pd.read_csv(path)\n",
    "\n",
    "def coerce_zcta(series):\n",
    "    \"\"\"Return 5-digit, zero-padded strings; strips non-digit chars if present.\"\"\"\n",
    "    s = series.astype(str).str.extract(r\"(\\d{3,5})\", expand=False)\n",
    "    return s.fillna(\"\").str.zfill(5)\n",
    "\n",
    "def pct_rank(s: pd.Series) -> pd.Series:\n",
    "    s = pd.to_numeric(s, errors='coerce')\n",
    "    return s.rank(pct=True, method='average').fillna(0.5)\n",
    "\n",
    "def nonint_fraction(x: pd.Series) -> float:\n",
    "    x = pd.to_numeric(x, errors='coerce')\n",
    "    return float((np.abs(x - np.round(x)) > 1e-9).mean())\n",
    "\n",
    "# ---------- Optional loaders: AQI + HHI ----------\n",
    "def read_aqi_data(file_path):\n",
    "    \"\"\"\n",
    "    Reads AQI/PM2.5-like CSV and aggregates annual weighted average per ZIP by Observation Count.\n",
    "    Returns: aqi_annual: [zip, aqi, obs_total]\n",
    "    \"\"\"\n",
    "    df = read_csv_smart(file_path)\n",
    "    zip_cols = [c for c in df.columns if str(c).upper().startswith('ZIP')]\n",
    "    if not zip_cols:\n",
    "        raise KeyError(\"AQI CSV needs a ZIP column.\")\n",
    "    zip_col = zip_cols[-1]\n",
    "    df['zip'] = df[zip_col].astype(str).str.extract(r'(\\d{5})')[0].fillna('').str.zfill(5)\n",
    "\n",
    "    if 'Arithmetic Mean' not in df.columns or 'Observation Count' not in df.columns:\n",
    "        raise KeyError(\"AQI CSV must include 'Arithmetic Mean' and 'Observation Count' columns.\")\n",
    "    val_col = 'Arithmetic Mean'\n",
    "    w_col   = 'Observation Count'\n",
    "    df[val_col] = pd.to_numeric(df[val_col], errors='coerce')\n",
    "    df[w_col]   = pd.to_numeric(df[w_col], errors='coerce').fillna(0)\n",
    "\n",
    "    # Restrict to PM2.5 if present\n",
    "    if 'Parameter Name' in df.columns:\n",
    "        df = df[df['Parameter Name'].astype(str).str.contains('PM2.5', na=False)]\n",
    "\n",
    "    df = df.dropna(subset=['zip', val_col])\n",
    "    df = df[df[w_col] > 0]\n",
    "\n",
    "    grp_annual = df.groupby('zip', as_index=False).apply(\n",
    "        lambda g: pd.Series({\n",
    "            'aqi': np.average(g[val_col], weights=g[w_col]),\n",
    "            'obs_total': g[w_col].sum()\n",
    "        })\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return grp_annual[['zip','aqi','obs_total']]\n",
    "\n",
    "def read_hhi_excel(file_path):\n",
    "    \"\"\"Reads Heat-Health Index Excel -> [zip, heat_hhb, nbe_score?, hhi_overall?]\"\"\"\n",
    "    df = pd.read_excel(file_path, dtype={'ZCTA': str})\n",
    "    if 'ZCTA' not in df.columns:\n",
    "        raise ValueError(\"HHI Excel must contain 'ZCTA' column.\")\n",
    "    df['zip'] = df['ZCTA'].astype(str).str.extract(r'(\\d{5})')[0].fillna('').str.zfill(5)\n",
    "\n",
    "    out = pd.DataFrame({'zip': df['zip']})\n",
    "    if 'HHB_SCORE' in df.columns:\n",
    "        out['heat_hhb'] = pd.to_numeric(df['HHB_SCORE'], errors='coerce')\n",
    "    if 'NBE_SCORE' in df.columns:\n",
    "        out['nbe_score'] = pd.to_numeric(df['NBE_SCORE'], errors='coerce')\n",
    "    if 'OVERALL_SCORE' in df.columns:\n",
    "        out['hhi_overall'] = pd.to_numeric(df['OVERALL_SCORE'], errors='coerce')\n",
    "\n",
    "    return out.dropna(subset=['zip']).drop_duplicates(subset=['zip'])\n",
    "\n",
    "# ---------- Load & prepare each source ----------\n",
    "with Step(\"Load FINANCIAL (income)\"):\n",
    "    fin = read_csv_smart(FINANCIAL_CSV)\n",
    "    zcta_col = None\n",
    "    for cand in [\"ZCTA5\",\"zcta5\",\"ZCTA\",\"zcta\",\"ZIP\",\"Zip\",\"NAME\",\"Name\",\"name\"]:\n",
    "        if cand in fin.columns:\n",
    "            zcta_col = cand; break\n",
    "    if zcta_col is None:\n",
    "        raise KeyError(f\"Could not find a ZCTA/ZIP column in {FINANCIAL_CSV}.\")\n",
    "    if \"S1901_C01_012E\" not in fin.columns:\n",
    "        raise KeyError(\"Missing S1901_C01_012E (median HH income) in FINANCIAL_CSV.\")\n",
    "    fin = fin.rename(columns={zcta_col:\"ZCTA5\"})\n",
    "    fin[\"ZCTA5\"] = coerce_zcta(fin[\"ZCTA5\"])\n",
    "    fin = fin[[\"ZCTA5\",\"S1901_C01_012E\"]].copy()\n",
    "    fin[\"S1901_C01_012E\"] = pd.to_numeric(fin[\"S1901_C01_012E\"], errors=\"coerce\")\n",
    "    stamp(f\"FIN rows={len(fin)}, null income={fin['S1901_C01_012E'].isna().sum()}\")\n",
    "\n",
    "with Step(\"Load HEALTH (poor general health %)\"):\n",
    "    hlth = read_csv_smart(HEALTH_CSV)\n",
    "    if \"ZCTA5\" not in hlth.columns:\n",
    "        for cand in [\"ZCTA\",\"zcta\",\"ZIP\",\"Zip\",\"name\",\"NAME\"]:\n",
    "            if cand in hlth.columns:\n",
    "                hlth = hlth.rename(columns={cand:\"ZCTA5\"})\n",
    "                break\n",
    "    if \"ZCTA5\" not in hlth.columns or \"GHLTH_CrudePrev\" not in hlth.columns:\n",
    "        raise KeyError(\"HEALTH_CSV must contain ZCTA5 and GHLTH_CrudePrev.\")\n",
    "    hlth[\"ZCTA5\"] = coerce_zcta(hlth[\"ZCTA5\"])\n",
    "    hlth[\"GHLTH_CrudePrev\"] = pd.to_numeric(hlth[\"GHLTH_CrudePrev\"], errors=\"coerce\")\n",
    "    hlth = hlth[[\"ZCTA5\",\"GHLTH_CrudePrev\"]]\n",
    "    stamp(f\"HEALTH rows={len(hlth)}, null health%={hlth['GHLTH_CrudePrev'].isna().sum()}\")\n",
    "\n",
    "with Step(\"Load PHARMACY (access)\"):\n",
    "    ph = read_csv_smart(PHARMACY_CSV)\n",
    "    for needed in [\"ZIP\",\"NAME\"]:\n",
    "        if needed not in ph.columns:\n",
    "            raise KeyError(f\"PHARMACY_CSV must contain {needed}.\")\n",
    "    ph[\"ZCTA5\"] = coerce_zcta(ph[\"ZIP\"])\n",
    "    ph_cnt = ph.groupby(\"ZCTA5\", dropna=False)[\"NAME\"].nunique(dropna=True).reset_index()\n",
    "    ph_cnt = ph_cnt.rename(columns={\"NAME\":\"pharmacies_count\"})\n",
    "    stamp(f\"PHARMACY unique ZCTA5={ph_cnt['ZCTA5'].nunique()}, pharmacies={ph_cnt['pharmacies_count'].sum()}\")\n",
    "\n",
    "with Step(\"Load POPULATION (skiprows=10 + autodetect)\"):\n",
    "    pop = read_csv_smart(POPULATION_CSV, skiprows=10)\n",
    "    code_col = None\n",
    "    for cand in [\"ZCTA5\",\"ZCTA\",\"ZIP\",\"Zip\",\"GEOID\",\"geoid\",\"NAME\",\"name\"]:\n",
    "        if cand in pop.columns:\n",
    "            code_col=cand; break\n",
    "    if code_col is None:\n",
    "        obj_cols = [c for c in pop.columns if pop[c].dtype == object]\n",
    "        code_col = obj_cols[0] if obj_cols else pop.columns[0]\n",
    "    pop = pop.rename(columns={code_col:\"ZCTA5\"})\n",
    "    pop[\"ZCTA5\"] = coerce_zcta(pop[\"ZCTA5\"])\n",
    "\n",
    "    pop_col = None\n",
    "    for cand in [\"POP\",\"Population\",\"population\",\"TOTAL_POP\",\"TotPop\",\"DP05_0001E\",\"pop\"]:\n",
    "        if cand in pop.columns:\n",
    "            pop_col=cand; break\n",
    "    if pop_col is None:\n",
    "        num_cols = [c for c in pop.columns if pd.api.types.is_numeric_dtype(pop[c])]\n",
    "        sums = {c: pd.to_numeric(pop[c], errors=\"coerce\").sum(skipna=True) for c in num_cols}\n",
    "        pop_col = max(sums, key=sums.get) if sums else None\n",
    "    if pop_col is None:\n",
    "        raise KeyError(\"Could not infer population column in POPULATION_CSV.\")\n",
    "\n",
    "    land_col = None\n",
    "    for cand in [\"land_area_km2\",\"Land_Area_km2\",\"ALAND_KM2\",\"aland_km2\",\"ALAND\",\"area\",\"AREA_KM2\",\"ALAND_SQMI\",\"AREALAND\"]:\n",
    "        if cand in pop.columns:\n",
    "            land_col = cand; break\n",
    "\n",
    "    keep_cols = [\"ZCTA5\", pop_col] + ([land_col] if land_col else [])\n",
    "    pop = pop[keep_cols].copy()\n",
    "    pop = pop.rename(columns={pop_col:\"population\"})\n",
    "    pop[\"population\"] = pd.to_numeric(pop[\"population\"], errors=\"coerce\")\n",
    "    if land_col:\n",
    "        pop = pop.rename(columns={land_col:\"land_area_raw\"})\n",
    "        pop[\"land_area_raw\"] = pd.to_numeric(pop[\"land_area_raw\"], errors=\"coerce\")\n",
    "    stamp(f\"POP rows={len(pop)}, null pop={pop['population'].isna().sum()}, land_col={land_col}\")\n",
    "\n",
    "# Optional: load AQI + HHI\n",
    "try:\n",
    "    with Step(\"Load AQI (annual weighted PM2.5)\"):\n",
    "        aqi_annual = read_aqi_data(AQI_CSV)\n",
    "        stamp(f\"AQI rows={len(aqi_annual)} (coverage ~{100*len(aqi_annual)/max(1, pop['ZCTA5'].nunique()):.1f}%)\")\n",
    "except Exception as e:\n",
    "    aqi_annual = None\n",
    "    warnings.warn(f\"AQI not loaded: {e}\")\n",
    "\n",
    "try:\n",
    "    with Step(\"Load HHI (heat vulnerability)\"):\n",
    "        hhi = read_hhi_excel(HHI_XLSX)\n",
    "        stamp(f\"HHI rows={len(hhi)}\")\n",
    "except Exception as e:\n",
    "    hhi = None\n",
    "    warnings.warn(f\"HHI not loaded: {e}\")\n",
    "\n",
    "# ---------- Merge all to ZCTA frame ----------\n",
    "with Step(\"Merge all features by ZCTA/ZIP\"):\n",
    "    df = fin.merge(hlth, on=\"ZCTA5\", how=\"outer\") \\\n",
    "            .merge(pop, on=\"ZCTA5\", how=\"outer\") \\\n",
    "            .merge(ph_cnt, on=\"ZCTA5\", how=\"left\")\n",
    "    if aqi_annual is not None and not aqi_annual.empty:\n",
    "        df = df.merge(aqi_annual.rename(columns={'zip':'ZCTA5'}), on=\"ZCTA5\", how=\"left\")\n",
    "    if hhi is not None and not hhi.empty:\n",
    "        df = df.merge(hhi.rename(columns={'zip':'ZCTA5'}), on=\"ZCTA5\", how=\"left\")\n",
    "    stamp(f\"Merged shape: {df.shape}\")\n",
    "\n",
    "# ---------- Feature engineering ----------\n",
    "with Step(\"Feature engineering\"):\n",
    "    # Rename to friendly\n",
    "    df[\"median_income\"]   = pd.to_numeric(df[\"S1901_C01_012E\"], errors=\"coerce\")\n",
    "    df[\"poor_health_pct\"] = pd.to_numeric(df[\"GHLTH_CrudePrev\"], errors=\"coerce\")\n",
    "    df[\"pharmacies_count\"]= pd.to_numeric(df[\"pharmacies_count\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "    # Impute income & health with national medians\n",
    "    for col in [\"median_income\",\"poor_health_pct\"]:\n",
    "        med = df[col].median(skipna=True)\n",
    "        df[col] = df[col].fillna(med)\n",
    "\n",
    "    # Access: population-based scarcity (people per pharmacy; higher = worse)\n",
    "    denom = df[\"pharmacies_count\"].replace(0, 1)  # keep finite for 0-pharmacy ZIPs\n",
    "    df[\"pop_per_pharmacy\"] = np.where(df[\"population\"].gt(0), df[\"population\"] / denom, np.nan)\n",
    "\n",
    "    # Density (optional; convert ALAND sq meters to km2 if present)\n",
    "    if \"land_area_raw\" in df.columns:\n",
    "        med_area = np.nanmedian(df[\"land_area_raw\"])\n",
    "        if np.isfinite(med_area) and med_area > 1e5:\n",
    "            df[\"land_area_km2\"] = df[\"land_area_raw\"] / 1e6\n",
    "        else:\n",
    "            df[\"land_area_km2\"] = df[\"land_area_raw\"]\n",
    "        df[\"pop_density\"] = np.where(df[\"land_area_km2\"].gt(0), df[\"population\"]/df[\"land_area_km2\"], np.nan)\n",
    "    else:\n",
    "        df[\"pop_density\"] = np.nan\n",
    "\n",
    "    # AQI/HHI numeric\n",
    "    if \"aqi\" in df.columns:       df[\"aqi\"] = pd.to_numeric(df[\"aqi\"], errors=\"coerce\")\n",
    "    if \"heat_hhb\" in df.columns:  df[\"heat_hhb\"] = pd.to_numeric(df[\"heat_hhb\"], errors=\"coerce\")\n",
    "\n",
    "    # Percentile features (0..1, higher = worse)\n",
    "    df[\"income_pct_inv\"]  = 1 - pct_rank(df[\"median_income\"])\n",
    "    df[\"health_pct\"]      = pct_rank(df[\"poor_health_pct\"])\n",
    "    df[\"access_pct_inv\"]  = pct_rank(df[\"pop_per_pharmacy\"])\n",
    "    df[\"density_pct\"]     = pct_rank(df[\"pop_density\"]) if df[\"pop_density\"].notna().any() else 0.5\n",
    "    df[\"aqi_pct\"]         = pct_rank(df[\"aqi\"])         if \"aqi\" in df.columns else 0.5\n",
    "    df[\"heat_pct\"]        = pct_rank(df[\"heat_hhb\"])    if \"heat_hhb\" in df.columns else 0.5\n",
    "\n",
    "# ---------- Composite + IsolationForest ----------\n",
    "with Step(\"Compute composite & train IsolationForest\"):\n",
    "    # Coverage checks (fraction of non-null)\n",
    "    cov = {\n",
    "        'aqi':    (\"aqi\" in df.columns) and df[\"aqi\"].notna().mean(),\n",
    "        'heat':   (\"heat_hhb\" in df.columns) and df[\"heat_hhb\"].notna().mean(),\n",
    "        'density': df[\"pop_density\"].notna().mean()\n",
    "    }\n",
    "    print(\"Coverage:\", cov)\n",
    "\n",
    "    use_aqi  = bool(cov[\"aqi\"])  and (cov[\"aqi\"]  >= 0.30)\n",
    "    use_heat = bool(cov[\"heat\"]) and (cov[\"heat\"] >= 0.30)\n",
    "    use_dens = bool(cov[\"density\"]) and (cov[\"density\"] >= 0.20)\n",
    "\n",
    "    # Base weights (sum ~1 before normalization)\n",
    "    w_income, w_health, w_access = 0.30, 0.35, 0.30\n",
    "    w_aqi   = 0.05 if use_aqi  else 0.00\n",
    "    w_heat  = 0.05 if use_heat else 0.00\n",
    "    w_dens  = 0.00 if not use_dens else 0.02  # keep small even if available\n",
    "\n",
    "    # Normalize to sum=1\n",
    "    Wsum = w_income + w_health + w_access + w_aqi + w_heat + w_dens\n",
    "    w_income, w_health, w_access, w_aqi, w_heat, w_dens = [w/Wsum for w in [w_income, w_health, w_access, w_aqi, w_heat, w_dens]]\n",
    "\n",
    "    # Composite (transparent)\n",
    "    df[\"composite\"] = (\n",
    "        w_income * df[\"income_pct_inv\"] +\n",
    "        w_health * df[\"health_pct\"] +\n",
    "        w_access * df[\"access_pct_inv\"] +\n",
    "        w_aqi    * (df[\"aqi_pct\"]   if use_aqi  else 0) +\n",
    "        w_heat   * (df[\"heat_pct\"]  if use_heat else 0) +\n",
    "        w_dens   * (df[\"density_pct\"] if use_dens else 0)\n",
    "    )\n",
    "\n",
    "    # IF features = same percentile vector\n",
    "    feat_cols = [\"income_pct_inv\",\"health_pct\",\"access_pct_inv\"]\n",
    "    if use_aqi:  feat_cols.append(\"aqi_pct\")\n",
    "    if use_heat: feat_cols.append(\"heat_pct\")\n",
    "    if use_dens: feat_cols.append(\"density_pct\")\n",
    "    X = df[feat_cols].fillna(0.5).to_numpy()\n",
    "\n",
    "    iforest = IsolationForest(random_state=42, contamination=CONTAMINATION, n_estimators=150, n_jobs=-1)\n",
    "    iforest.fit(X)\n",
    "    anom = -iforest.decision_function(X)                     # invert so higher = more anomalous\n",
    "    anom = (anom - anom.min()) / (anom.max() - anom.min() + 1e-12)  # 0..1\n",
    "    df[\"iforest_anomaly\"] = anom\n",
    "\n",
    "    # Final score = blend\n",
    "    df[\"IFAE_score\"] = 0.5*df[\"composite\"] + 0.5*df[\"iforest_anomaly\"]\n",
    "\n",
    "# ---------- Finalize outputs ----------\n",
    "with Step(\"Finalize outputs\"):\n",
    "    out = Path(OUT_DIR); out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    keep = [\n",
    "        \"ZCTA5\",\"IFAE_score\",\"composite\",\"iforest_anomaly\",\n",
    "        \"median_income\",\"poor_health_pct\",\"population\",\"pharmacies_count\",\n",
    "        \"pop_per_pharmacy\",\"income_pct_inv\",\"health_pct\",\"access_pct_inv\",\n",
    "        \"density_pct\",\"pop_density\"\n",
    "    ]\n",
    "    if \"aqi\" in df.columns:       keep += [\"aqi\",\"aqi_pct\",\"obs_total\"]\n",
    "    if \"heat_hhb\" in df.columns:  keep += [\"heat_hhb\",\"heat_pct\"]\n",
    "    if \"land_area_km2\" in df.columns: keep += [\"land_area_km2\"]\n",
    "\n",
    "    ranked = df[keep].copy().sort_values(\"IFAE_score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Save everything\n",
    "    out_full   = out / \"national_ifae_rank.csv\"\n",
    "    out_top    = out / \"top5_ifae.csv\"\n",
    "    out_bottom = out / \"bottom5_ifae.csv\"\n",
    "    ranked.to_csv(out_full, index=False)\n",
    "\n",
    "    # Population gate for top-k presentation\n",
    "    eligible = ranked[ ranked[\"population\"].fillna(0) >= MIN_POP_TOPK ]\n",
    "    top_presentable = eligible.head(TOP_K)\n",
    "    bottom_presentable = ranked.tail(TOP_K)\n",
    "\n",
    "    top_presentable.to_csv(out_top, index=False)\n",
    "    bottom_presentable.to_csv(out_bottom, index=False)\n",
    "\n",
    "    stamp(f\"Wrote {out_full}\")\n",
    "    stamp(f\"Wrote {out_top} (pop â‰¥ {MIN_POP_TOPK})\")\n",
    "    stamp(f\"Wrote {out_bottom}\")\n",
    "\n",
    "    print(\"\\nTop 5 (pop â‰¥ {:,}) preview:\\n\".format(MIN_POP_TOPK), top_presentable.head(5).to_string(index=False))\n",
    "    print(\"\\nBottom 5 preview:\\n\", bottom_presentable.tail(5).to_string(index=False))\n",
    "\n",
    "stamp(\"All done. ðŸš€\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
